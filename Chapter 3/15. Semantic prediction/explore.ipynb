{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amazon Reviews sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import  torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = datasets.AmazonReviewFull(root='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/AmazonReviewFull/amazon_review_full_csv/train.csv',nrows=5000,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/AmazonReviewFull/amazon_review_full_csv/test.csv',nrows=1000,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **merging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['reviews'] = train.iloc[:,1]+ ' ' +train.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck</td>\n",
       "      <td>Gave this to my dad for a gag gift after direc...</td>\n",
       "      <td>more like funchuck Gave this to my dad for a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>I hope a lot of people hear this cd. We need m...</td>\n",
       "      <td>Inspiring I hope a lot of people hear this cd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST</td>\n",
       "      <td>The music of Yasunori Misuda is without questi...</td>\n",
       "      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true</td>\n",
       "      <td>Probably the greatest soundtrack in history! U...</td>\n",
       "      <td>Too good to be true Probably the greatest soun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2</td>\n",
       "      <td>Waste oF $MONEY$</td>\n",
       "      <td>Waste Of Time &amp; Money... I found that if you w...</td>\n",
       "      <td>Waste oF $MONEY$ Waste Of Time &amp; Money... I fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4</td>\n",
       "      <td>trying to win better</td>\n",
       "      <td>This book cuts down the odds with a better cha...</td>\n",
       "      <td>trying to win better This book cuts down the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2</td>\n",
       "      <td>don\"t waste your money just buy the the lotter...</td>\n",
       "      <td>this book have almost the same information as ...</td>\n",
       "      <td>don\"t waste your money just buy the the lotter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2</td>\n",
       "      <td>The odds are against you not for you.</td>\n",
       "      <td>Winning is pure luck. There is no amount of st...</td>\n",
       "      <td>The odds are against you not for you. Winning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "      <td>Incorrect Product Information</td>\n",
       "      <td>The actual model of this meter is the i410, I ...</td>\n",
       "      <td>Incorrect Product Information The actual model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1  \\\n",
       "0     3                                 more like funchuck   \n",
       "1     5                                          Inspiring   \n",
       "2     5              The best soundtrack ever to anything.   \n",
       "3     4                                   Chrono Cross OST   \n",
       "4     5                                Too good to be true   \n",
       "...  ..                                                ...   \n",
       "4995  2                                   Waste oF $MONEY$   \n",
       "4996  4                               trying to win better   \n",
       "4997  2  don\"t waste your money just buy the the lotter...   \n",
       "4998  2              The odds are against you not for you.   \n",
       "4999  1                      Incorrect Product Information   \n",
       "\n",
       "                                                      2  \\\n",
       "0     Gave this to my dad for a gag gift after direc...   \n",
       "1     I hope a lot of people hear this cd. We need m...   \n",
       "2     I'm reading a lot of reviews saying that this ...   \n",
       "3     The music of Yasunori Misuda is without questi...   \n",
       "4     Probably the greatest soundtrack in history! U...   \n",
       "...                                                 ...   \n",
       "4995  Waste Of Time & Money... I found that if you w...   \n",
       "4996  This book cuts down the odds with a better cha...   \n",
       "4997  this book have almost the same information as ...   \n",
       "4998  Winning is pure luck. There is no amount of st...   \n",
       "4999  The actual model of this meter is the i410, I ...   \n",
       "\n",
       "                                                reviews  \n",
       "0     more like funchuck Gave this to my dad for a g...  \n",
       "1     Inspiring I hope a lot of people hear this cd....  \n",
       "2     The best soundtrack ever to anything. I'm read...  \n",
       "3     Chrono Cross OST The music of Yasunori Misuda ...  \n",
       "4     Too good to be true Probably the greatest soun...  \n",
       "...                                                 ...  \n",
       "4995  Waste oF $MONEY$ Waste Of Time & Money... I fo...  \n",
       "4996  trying to win better This book cuts down the o...  \n",
       "4997  don\"t waste your money just buy the the lotter...  \n",
       "4998  The odds are against you not for you. Winning ...  \n",
       "4999  Incorrect Product Information The actual model...  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **dropping other merged individual columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([1,2],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **encoding** labels(1-5) -> (0-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some ordinal encoding on labels\n",
    "train[0] = train[0].apply(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 0, 1])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get spacy work done**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fb30d55b100>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **tokenization, lemmatization, punctuation removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'version', 'little', 'bit', 'harsh', 'come', 'prep']\n"
     ]
    }
   ],
   "source": [
    "text = 'It can be done better than this, because this version little bit harsh when it comes to prep'\n",
    "print(prep(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **textual prep. is almost done, yet word 2 vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexer = FastText('simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fast text has vocab, it can map words to indexes in that vocab\n",
    "#we cleaned text, got token lemmatized, now we can get indexes for each word\n",
    "word_indexer.stoi['chicken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # but there is a case when word is not existed in that vocab\n",
    "# word_indexer.stoi('Saidalikhon')\n",
    "# #we should handle it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**token endcoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_encoder(token,word_indexer):\n",
    "    if token == '<pad>':\n",
    "        return 1\n",
    "    else:\n",
    "        try:\n",
    "            return word_indexer.stoi[token]\n",
    "        except:\n",
    "            if type(token) != str :\n",
    "                print(f'expected str, but got {type(token)} instead.')\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_encoder('Saidalikhon',word_indexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**text encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encoder(tokens,word_indexer):\n",
    "    '''\n",
    "    input - list of lemmatized tokens\n",
    "    returns - list of encoded tokens\n",
    "    '''\n",
    "    return [token_encoder(token,word_indexer) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[624, 216, 1044, 0, 13200, 178, 6975, 220]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'It might be the case , when you got job done in Pytorch, then realise there is a better and efficient way of it.'\n",
    "text_encoder(prep(text),word_indexer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have reviews, with different length\n",
    "#but our model expects the same dimensionality across its life cycle\n",
    "#so we should add padding(if review has less amount word than max_length)\n",
    "#or we should slice the review if it has more than max_length\n",
    "# 5 * [1] -> [1,1,1,1,1], 0 * [1] -> [], -x * [1] -> []\n",
    "def padding(list_indexed,max_length,pad=1):\n",
    "    #padding short reviews\n",
    "    res = list_indexed + (max_length - len(list_indexed))*[pad]\n",
    "    # slicing prior to return, if review is longer\n",
    "    return res[:max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[624, 216, 1044, 0, 13200, 178, 6975, 220, 1, 1]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'It might be the case , when you got job done in Pytorch, then realise there is a better and efficient way of it.'\n",
    "padding(text_encoder(prep(text),word_indexer),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[624, 216, 1044, 0, 13200]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding(text_encoder(prep(text),word_indexer),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**splitting into train and val**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['reviews'].values\n",
    "y=train[0].values\n",
    "x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,x,y,max_length=32):\n",
    "        self.max_length = max_length\n",
    "        self.vec = FastText('simple')\n",
    "        self.vectorizer = lambda x: self.vec.vectors[x]\n",
    "        self.vec.vectors[0] = torch.zeros(self.vec.vectors[0].shape[0])\n",
    "        self.vec.vectors[0] = -torch.ones(self.vec.vectors[0].shape[0])\n",
    "        self.labels = y\n",
    "        self.inputs = [padding(text_encoder(prep(review),self.vec),self.max_length) for review in x]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert len(self.inputs[i]) == self.max_length\n",
    "        return self.inputs[i],self.labels[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we create our custom collate function, later use inside dataloader, as collate function to batchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      " [2847, 930, 0, 0, 31413, 2895, 5828, 5072, 3776, 0, 216, 229, 338, 14262, 930, 437, 0, 437, 16633, 30659, 3192, 1368, 1358, 14262, 1948, 148, 0, 2895, 6143, 1736, 5828, 0]\n"
     ]
    }
   ],
   "source": [
    "#each item of the the set, contains (input,label)\n",
    "print(trainset[0][1],'\\n',trainset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(x_train,y_train)\n",
    "def collate(batch,vectorizer=FastText('simple').vectors):\n",
    "    #inner torch.stack is stacking vectorized words into review tensor\n",
    "    #outer torch.stack is stacking that review into batch tensor\n",
    "    inputs = torch.stack([torch.stack([vectorizer[token] for token in item[0]]) for item in batch])\n",
    "    #\n",
    "    #converting labels into Long type tensors, as criterion functions expects that dtype\n",
    "    labels = torch.LongTensor([item[1] for item in batch])\n",
    "    return inputs, labels\n",
    "dataloader_tr = DataLoader(trainset,batch_size=64,collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 300])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader_tr))[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = CustomDataset(x_val,y_val)\n",
    "dataloader_val = DataLoader(valset,batch_size=64,collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim =300\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,hidden1,hidden2,out_dim,max_length=32):\n",
    "        super(Model,self).__init__()\n",
    "        self.fc = nn.Linear(embed_dim*max_length,hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1,hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2,out_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        z = F.relu(self.fc(x))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = F.log_softmax(self.fc3(z),dim=1)\n",
    "\n",
    "        return z\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 1 out of 2 epochs \n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "1.5515178442001343\n",
      "running 2 out of 2 epochs \n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "1.0193592309951782\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "model = Model(100,50,5)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.003)\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(f'running {epoch+1} out of {epochs} epochs ')\n",
    "    model.train()\n",
    "    for i,(x_tr,y_tr) in enumerate(iter(dataloader_tr)):\n",
    "        optimizer.zero_grad()\n",
    "        print(i)\n",
    "        pred_tr = model.forward(x_tr.view(x_tr.shape[0],-1))\n",
    "        loss = criterion(pred_tr,y_tr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss.item())\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d51a5fea8c6d96b3ba385d558c569b949285f78f32378af2035738b4398847"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('NLP_ENV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
