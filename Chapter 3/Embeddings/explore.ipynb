{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(pth):\n",
    "    save_path = 'clean.txt'\n",
    "    with open(pth,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            lines[i]= lines[i].replace('\"','').replace('\\'','').replace(',','').replace('.','').\\\n",
    "                replace('!','').replace(':','').replace(';','').replace('-','').replace('_','').\\\n",
    "                    replace('[','').replace(']','').lower()\n",
    "        with open(save_path,'w') as nw:\n",
    "            nw.writelines(lines)\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clean.txt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth='blakepoems.txt'\n",
    "cleaning(pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting each line as a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(path):\n",
    "    with open(path,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        result = [line.split() for line in lines]\n",
    "        i=0\n",
    "        \n",
    "    #cleaning empty new lines\n",
    "    while i<len(result):\n",
    "        if result[i] == []:\n",
    "            result.pop(i)\n",
    "        else:\n",
    "            i+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = get_sentences('clean.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting mapper dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(sentences):\n",
    "    voca = []\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word not in voca:\n",
    "                voca.append(word)\n",
    "\n",
    "    w2i = {w:i for i,w in enumerate(voca)}\n",
    "    i2w = {i:w for i,w in enumerate(voca)}\n",
    "    return w2i,i2w,len(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i,i2w,voca_size = get_dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voca_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(sentences,w2i,rng):\n",
    "    pairs = []\n",
    "    for sentence in sentences:\n",
    "        token = [w2i[word] for word in sentence]\n",
    "        for center in range(len(token)):\n",
    "            for r in range(-rng,rng+1):\n",
    "                pair = center + r\n",
    "                if pair < 0 or pair >= len(token) or pair == center: \n",
    "                    continue\n",
    "                else:\n",
    "                    pairs.append((token[center],token[pair]))\n",
    "            \n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28056"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = get_pairs(l,w2i,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(pth,pair_interval):\n",
    "\n",
    "    #data cleaning\n",
    "    cleaned_file_path = cleaning(pth)\n",
    "\n",
    "    #tokenizing sentence into words\n",
    "    sentences = get_sentences(cleaned_file_path)\n",
    "\n",
    "    #getting mapper dictionaries and vocabulary size\n",
    "    w2i,i2w,voca_size = get_dict(sentences)\n",
    "\n",
    "    #getting pairs\n",
    "    pairs = get_pairs(sentences,w2i,pair_interval)\n",
    "\n",
    "    return pairs,voca_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = 'blakepoems.txt'\n",
    "pairs,voca_size = embed(pth,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20816"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c552931fb620b60b927d393c6464ee521e771bb8b6920714febc020bd5f2901f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
