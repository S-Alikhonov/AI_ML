{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Clasification: MNIST</h2>\n",
    "<div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Auxliary plotting function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load MNIST Dataset\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "plt.imshow(images[9].numpy().squeeze(), cmap='Greys_r');"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 251,
       "height": 248
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "images[1].numpy().squeeze()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.00392163,  0.00392163,  0.49803925,\n",
       "         1.        ,  1.        ,  1.        ,  0.00392163, -0.4980392 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.4980392 ,  0.49803925,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.00392163, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.00392163,\n",
       "         1.        ,  1.        ,  1.        ,  0.49803925,  0.00392163,\n",
       "         0.00392163,  0.49803925,  1.        ,  1.        ,  1.        ,\n",
       "         1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.4980392 ,  1.        ,\n",
       "         1.        ,  1.        , -0.4980392 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.49803925,\n",
       "         1.        ,  0.00392163, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.4980392 ,  1.        ,  1.        ,\n",
       "         0.49803925, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.00392163,\n",
       "         1.        ,  0.00392163, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.49803925,  1.        ,  0.49803925,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.49803925,  0.00392163, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.00392163,  1.        ,  1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.00392163, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  1.        ,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.00392163,  1.        ,  0.00392163, -0.4980392 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  1.        ,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  1.        ,  1.        ,  1.        ,  0.49803925,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  1.        ,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.49803925,  1.        ,  1.        ,  1.        ,  0.00392163,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  1.        ,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ,  0.00392163,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.00392163,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.49803925,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -0.4980392 ,  0.49803925,  1.        ,\n",
       "         0.00392163,  1.        ,  1.        ,  1.        ,  0.00392163,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  1.        ,  1.        ,  0.00392163,\n",
       "         0.00392163, -0.4980392 ,  1.        ,  0.49803925, -0.4980392 ,\n",
       "        -1.        ,  0.49803925,  1.        ,  1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.4980392 ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.00392163, -1.        , -1.        ,\n",
       "        -1.        ,  1.        ,  1.        ,  1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.00392163,  1.        ,  1.        ,  0.49803925, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.00392163,  1.        ,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.00392163,  1.        ,  1.        ,  0.00392163, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         1.        ,  1.        ,  1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.49803925,  1.        ,  1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.49803925,  0.49803925, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building networks with PyTorch\n",
    "\n",
    "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
    "\n",
    "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    # Defining the layers, 128, 64, 10 units each\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    # Forward pass through the network, returns the output logits\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sequential API\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size   = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "          ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0067, -0.0353,  0.0090,  ...,  0.0053,  0.0267, -0.0187],\n",
      "        [-0.0082,  0.0057,  0.0298,  ...,  0.0287,  0.0118,  0.0070],\n",
      "        [-0.0137,  0.0214, -0.0312,  ..., -0.0224, -0.0048,  0.0095],\n",
      "        ...,\n",
      "        [ 0.0178,  0.0120, -0.0231,  ..., -0.0085,  0.0280,  0.0275],\n",
      "        [ 0.0024, -0.0183, -0.0096,  ..., -0.0121,  0.0123,  0.0160],\n",
      "        [ 0.0308,  0.0150, -0.0261,  ...,  0.0342,  0.0006,  0.0051]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0175, -0.0315,  0.0295,  0.0327,  0.0145,  0.0305,  0.0234,  0.0207,\n",
      "        -0.0080,  0.0350,  0.0011, -0.0130,  0.0126,  0.0302, -0.0193,  0.0082,\n",
      "         0.0248, -0.0179, -0.0247, -0.0224,  0.0069,  0.0301,  0.0269,  0.0114,\n",
      "         0.0226,  0.0317,  0.0111, -0.0240, -0.0139, -0.0078,  0.0153,  0.0351,\n",
      "         0.0354, -0.0345,  0.0259, -0.0242,  0.0146,  0.0322,  0.0342, -0.0168,\n",
      "         0.0124, -0.0298,  0.0177,  0.0222,  0.0283,  0.0239, -0.0041,  0.0175,\n",
      "         0.0144, -0.0251, -0.0014,  0.0330,  0.0282,  0.0061, -0.0204, -0.0033,\n",
      "         0.0329, -0.0100, -0.0251, -0.0174, -0.0197,  0.0302,  0.0059, -0.0163,\n",
      "         0.0256,  0.0330, -0.0039, -0.0232,  0.0237, -0.0145, -0.0176, -0.0180,\n",
      "         0.0269, -0.0182, -0.0332,  0.0126, -0.0163,  0.0135,  0.0286,  0.0319,\n",
      "         0.0107,  0.0186, -0.0140, -0.0235, -0.0243,  0.0320,  0.0351, -0.0342,\n",
      "         0.0299,  0.0066,  0.0233,  0.0163,  0.0049,  0.0195,  0.0306,  0.0097,\n",
      "        -0.0284, -0.0071,  0.0209,  0.0058,  0.0287,  0.0284, -0.0027, -0.0314,\n",
      "         0.0021,  0.0349,  0.0353, -0.0158, -0.0257,  0.0190, -0.0170,  0.0074,\n",
      "         0.0320,  0.0323,  0.0013, -0.0279,  0.0129, -0.0174, -0.0120,  0.0144,\n",
      "         0.0287,  0.0304, -0.0042, -0.0027, -0.0024, -0.0139, -0.0228, -0.0315],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# Set biases to all zeros\n",
    "model.fc1.bias.data.fill_(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0027,  0.0037, -0.0102,  ..., -0.0104,  0.0079, -0.0089],\n",
       "        [ 0.0104, -0.0105,  0.0018,  ..., -0.0066, -0.0097,  0.0055],\n",
       "        [ 0.0030, -0.0126,  0.0150,  ...,  0.0006,  0.0074,  0.0019],\n",
       "        ...,\n",
       "        [-0.0038,  0.0084,  0.0011,  ...,  0.0106,  0.0001,  0.0156],\n",
       "        [ 0.0080, -0.0172,  0.0028,  ..., -0.0086, -0.0034,  0.0097],\n",
       "        [ 0.0030, -0.0004,  0.0127,  ..., -0.0012, -0.0002,  0.0073]])"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1: Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "print(img_idx)\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAGHCAYAAABf8fH3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAABYlAAAWJQFJUiTwAAAsIUlEQVR4nO3deZgddZXw8e8JYQlLAogQATGAsijOSKIooMgyMjpxwQXHd14Y92VEHRfmFRcUZ3QmzOgIwigiKgrOoKK4gQsqCArqTLM4gcgitAgiEJZASAiQnPePqjbX5t5Oded2163q7+d56qncqlNV51bfdJ8+/auqyEwkSZKktplRdwKSJEnSZLDQlSRJUitZ6EqSJKmVLHQlSZLUSha6kiRJaiULXUmSJLWSha4kSZJayUJXkiRJrWShK0mSpFay0JUkSVIrWehKkiSplSx0JUmS1EoWupIkSWolC11JkoCIyHKaV3cu00FEDJfn+8CmHDcijiu3Pb3qfiPiwHL58MQy1vqw0JUktUpEbBoRfxcR346ImyJiRUTcHxE3RsTZEXFERMyqO8+p0lGAdU6rI+LOiLg4It4REZvWned0FBGHlcXzgXXn0lYz605AkqR+iYgXAKcCczsW3w+sAeaV00uB4yPiyMz88VTnWKP7geXlvzcCtgaeWU6vi4iDMvP2upJriKXANcCt49hmRbnNLV3WHQa8svz3heuTmLqzoytJaoWIeBXwDYoi9xrgSGCbzNw8M2cDWwIvoygotgcOqCPPGn00M+eW09bANsBHgASeSPELgsaQmSdn5h6Z+Z5xbPPLcptDJjM3dWehK0lqvIj4M+AUip9r5wF7Z+aZmXnnSExmLsvMr2XmQcBfA/fVk+1gyMw7M/P9wOfLRS+KiO3rzEnqNwtdSVIbfATYmOLPw3+TmSvHCs7MrwD/XmXHEbFBRBwUESdGxFBE3BYRD0bE7yPinIg4eIxtZ0TEqyLignJM7EMRcUdEXBURn4uI53bZZueI+FREXBsRK8sxxr+NiAsj4j0RsU2VvMfhvzr+Pb8jjz9enBcRe0bEFyLid+V7+MaonPeOiDPL9asiYmlEfD8iXlolgYjYKSJOK7d/oBxP/dGImNMjfqOIWBgRn4mIK8vjPVCepy9FxIJJOm7Pi9HGOMYjLkYbWcbaYQsfHD2Ouoz7QPn6f9ZxjFeXcb+LCGu7Do7RlSQ1WkTsACwsX34iM5dV2S4zs+Ih9gQ6x/KuAh4EHkMxxvKwiHhfZv5zl23PAP6m4/UyYDbFsIEnltP3RlZGxHyKoRVblIseohhbu1M5PRu4vHObPugcOzq7y/pnUXTLN6Xogj/cuTIi3gB8irXNs3sohokcChwaEWcCr8rM1T2O/3jgK8CjKcYQJ8VY6ndRdJkPyMzRY2IPBb7d8XpFud1OFOf75RHxmsw8o8cxJ3rcfnkQuA2YA2zCn46f7vQ54IPAgoh4cmb+b4/9vaacfyEz1/Q72Saz6pckNd2BQJT//tYk7P9B4KvACyjG/87KzM2B7YBjgdXAhyPi6Z0bRcQBFEXXGuAdwOzM3JKisNkeeBXw01HH+ihFkfsLYH5mbpSZWwGbAU8DTqAolvtpp45/39Nl/SeB/waeXI513pSiGCQi9mNtkXs28Ngy3y2B91EUj0cAY41p/SjFe3pWZm5B8V4Po7jw6/HAF7pss5xiyMUhFOOwN8vMWcDjKM7RTODUiNipy7brc9y+yMxLMnMu8OWRXDrGT88t15GZNwPfL2Ne3W1fEfF4igsKk7XDUFSy0JUkNd2e5XwVxUVofZWZ12bmyzPzO5l520gnODNvz8wPAx+iKLTfNGrTZ5TzH2TmCZl5X7ldZuatmfmFzDy6xzZ/n5mXd+SwIjP/JzPfkZmX9vktvn7kMBQF7Wi3A8/LzMUd+f+mXPdPFLXEz4BXlIUZmbm87HAvKuPeHRHdusVQDDl5Xmb+tNx2TWZ+E3h5uf45EfHMzg0y88LMfE1m/njUOOybMvMdFJ3QTehRHE70uDX5TDk/IiI27LJ+pJt7UcfXRSULXUlS0z2qnN89juEI/TTyJ/T9Ry2/t5xvO45xkyPbPGa9sxpDOcb1iRFxGsXt1gDOysw7uoSf3G3Mc0RsDRxUvvyXHkMTjgceADYH/qpHOl/JzOtHL8zMC4BLypcv6/1uuur1NZns406Gb1MMc3g08PzOFeXn6m/Ll5+b4rwawUJXkqR1iIhZUTxY4cKIuL28IGvkoqGRzuvoOxb8kGLYw3zgwigeVLGuuxqcV86/GBGLIuIZPbp4E/HBjpxXAVcBry3X/Rx4c4/tenWQ96boZCfwk24B5XjpofLl/G4xjH3/2JH9PmLbiNg6Io6NiEvKC/0e7nh/55RhY53vCR13qmXmw6wdRjG6Q/2XwA4UvyCdPZV5NYUXo0mSmm7kT9dbRUT0u6sbEY+hKIp261h8P3A3xfjbDSguLtusc7vMvD4i/g44meKCrmeV+xumuJjs1M7hCaV/AHYH9gPeXU4PRMSlFOOET1/XHSXG0HnB02qK8alLKIrCs8qCqptuXV4oOowAyzKz24VUI24eFT9atwcpjF73J9tGxBMpLhDcrmPxfcBKisJ7I2BkbPO69l35uDU6Dfh/wPMiYrvMvK1cPjJs4azMXFFPaoPNjq4kqemWlPONKYrEfjuBosi9geLP/FuXD6HYtrxo6Bm9NszMzwE7A28HvklRlM+jGM87FBHvHRV/J8WFRc8BPkHRLd6IYojAJ4HFEbHjBN9H5wVPO2TmEzPzpeX9hnsVuVAUxWPZeIL5VBE9ln+eosi9DHgusEVmzs7M7cqvyeHr2H6ix61FZl5H0WWeSfEglJGhIy8sQxy20IOFriSp6X5C0cWDtT/4+yIiNgJeVL78v5n59cy8e1TYdoyhvIDtxMw8jKJDuA9FFzWAf4riYRed8ZmZP8zMv8/M+RTd4jcCdwG7AB9f3/fVJyOd3lkRMVbnc6Qw79UZHmt4wchY5T9uW95JYR+KAvyFmfn9Lh3lMb8mEznuADitnI8MXziC4pegqzPzF/WkNPgsdCVJjVZe6T8ytvWtY1zd/yciokrXbhvWdixHDzMY8RdVjgd/LGL/m6LjeDPFz+Exr+zPzLsz81RgpPv77KrHm2SXs/YXjIO6BZQPXhh5eMNlPfYz1vsZWde57R8L58zsNfygytdkvMedDCP3vK3yWTyb4vZvTyxvZTdS8NrNHYOFriSpDd5PcYHVjsB/RsQmYwVHxMuBd1bY772sLeae3GU/jwHe2uMYG/XaaXmHgofKlxuX8TMiYqxrZ1Z2xtctM+8CLihfvrvHnSXeTXGbr+Ws/WVktL+OiF1GLyzvQzxy14SvdqwauY/wdhGxbZftnsyfPqSjl/EedzKM3GVjy3UFZuYDwJnly48BT6H4DI31UIxpz0JXktR4mXkFcBRFUboQuLy8y8HWIzERMSciXhIRF1DcqH+Lrjv70/0up7gjAcDnIuIp5b5mRMQhFMMmenXj/jkizo6Iw0blsV1EfIJi7G4C55erZgPXR8T7IuLJEbHBqGN9pIz7PoPjWIqu5HzgrJHxwxGxeTn++JgyblFm3ttjHw8C3y0fPjHyfl/A2rsInJ+ZP+uIX0LRDQ/gy+UDE4iIDSPiJRTnc6yL4yZ63MlwVTl/bvlL07qM3FN3pBD/Tmbe3v+0WiQznZycnJycWjFRPNnqNooCcmS6j7Wd2ZFpGDhg1LYj6+aNWv501j5iNimKqJHXd1KM4U3Kpwp3bHfCqGMu65LHezvitxy17sFy/w93LPsNsOM4z8lwue1x49yu6/noEvdGivGySVH03jUq5zOBDcbI63UUD6UY+Vp1nuvrgMd02fbFHcfM8ryuKv/9W4rxqwkM9/m4x5XrTx9jvweOWn7gGLlsU36Ns3w/t5b7eURsxzb/3ZHn8+v+Pzfokx1dSVJrZOY3KC7YOoriT+U3U1ypPpOigDib4s/au2fmRRX3+QtgX+AbFLcU25CiQPo0xZ+Pr+yx6ceBt1HcbeFaig7kxsDvKDrKB2Tx9LAR91I8EOAE4JcUF0JtQXFbsP+meKTuU7J8+tigyMxPUzye+D8pCrXNKYr684HDM/OI7P4wiRHXA0+lGGu6jOJ2bcMUf55/ambe2uWY5wAHl8e4j+Jr8luKx/ruzdpbmo1l3Mftt8xcSjG++esUX+9HUzzG+HFjbPb1cn4r8N1JTbAFovztQJIkSQMuIs6nuNju+Mw8Zl3x052FriRJUgOU45GvLV/ull0eYaw/5dAFSZKkARcRmwMnUQyB+Y5FbjV2dCVJkgZURLyd4sl6cynGeD8ALMjMq2tMqzHs6EqSJA2uLSkuTlsNXAIcapFbnR1dSZIktZIdXUmSJLWSha4kSZJayUJXkiRJrTRzohs+Z8bhDu6V1Fjnr/lq1J2DJGly2dGVJElSK024oytJao6IuBGYDQzXnIokjdc84N7M3Hm8G1roStL0MHvWrFlb77nnnlvXnYgkjceSJUtYuXLlhLa10JWk6WF4zz333HpoaKjuPCRpXBYsWMBll102PJFtHaMrSZKkVrLQlSRJUitZ6EqSJKmVLHQlSZLUSha6kiRJaiULXUmSJLWSha4kSZJayUJXkiRJrWShK0mSpFay0JUkSVIrWehKkiSplSx0JUmS1Eoz605AkjQ1Ft+yjHnHnDtlxxtetHDKjiVJ3djRlSRJUitZ6EqSJKmVLHQlSZLUSha6kiRJaiULXUkaAFF4TUT8PCLui4gVEXF5RLwtIjaoOz9JaiILXUkaDF8APgvsDHwZ+AywEXAi8OWIiBpzk6RG8vZiklSziDgMOBK4EdgnM5eWyzcEvgK8FHglcHpNKUpSI9nRlaT6vaScf2ykyAXIzIeAY8uXb53yrCSp4Sx0Jal+c8v5DV3WjSybHxFbTk06ktQODl2QpPqNdHF37rJul45/7wH8fKwdRcRQj1V7TCAvSWo0O7qSVL/vlPN3RsTWIwsjYibwoY64raY0K0lqODu6klS/s4AjgOcBV0fEt4AVwF8AuwLXAU8AVq9rR5m5oNvystM7v18JS1IT2NGVpJpl5hrghcDRwB8o7sDwGuBm4JnAnWXo7bUkKEkNZUdXkgZAZj4MfKyc/igiZgFPAVYCV019ZpLUXHZ0JWmwHQlsAnylvN2YJKkiC11JGgARMbvLsqcBi4DlwD9OeVKS1HAOXZCkwXB+RKwEFgP3AU8C/gpYBbwkM7vdY1eSNAYLXUkaDGcDr6C4+8Is4PfAacCizByuMS9JaiwLXUkaAJn5b8C/1Z2HJLWJY3QlSZLUSha6kiRJaiWHLkjSNLHXDnMYWrSw7jQkacrY0ZUkSVIrWehKkiSplSx0JUmS1EoWupIkSWolL0bTlJqxySaV4m565/zK+7zqLZ+sHPvLVQ9Vjn3dlX9bOXarz25ROXaTb/+ycqwkSZo4C11JmiYW37KMececO6XHHPYuD5Jq5NAFSZIktZKFriRJklrJQleSJEmtZKErSQMiIhZGxA8i4uaIWBkRN0TEVyNi37pzk6QmstCVpAEQEccD3wHmA98DTgQuA14E/CwijqgxPUlqJO+6IEk1i4i5wNHAbcCfZebtHesOAn4M/CNwZj0ZSlIz2dGVpPo9juL78S86i1yAzLwAuA94dB2JSVKTWehKUv2uAx4E9omIbTpXRMQBwBbAD+tITJKazKELWm8zH7tj5diNv7SqUtwVu55UeZ+rMyrH7r1R9d/thp5W/a/ES+evrBy7cId/qBz76FMurRyr5srMuyLi3cC/A1dHxDeAO4FdgRcC5wNvrC9DSWomC11JGgCZeUJEDAOfA17fsep64PTRQxp6iYihHqv2WL8MJal5HLogSQMgIv4fcDZwOkUndzNgAXAD8KWI+Nf6spOkZrKjK0k1i4gDgeOBczLznR2rLouIFwPXAu+KiFMy84ax9pWZC3ocY4ji1mWSNG3Y0ZWk+j2/nF8wekVmrgB+SfH9eu+pTEqSms5CV5Lqt3E573ULsZHlD05BLpLUGha6klS/i8v5GyJih84VEfE8YH/gAeCSqU5MkprMMbqSVL+zKe6T+xfAkog4B/gDsCfFsIYAjsnMO+tLUZKax0JXkmqWmWsi4q+Ao4BXAC8GNgXuAs4DPpGZP6gxRUlqJAtdSRoAmfkQcEI5SZL6wDG6kiRJaiU7uupqxmabVY69+aQtKseev/OXK8X9aOXWlff5nFnVH787WbbZYFbl2LPe89HKsW8/+4WVY1cvdfimJEmd7OhKkiSplezoStI0sdcOcxhatLDuNCRpytjRlSRJUitZ6EqSJKmVLHQlSZLUSha6kiRJaiUvRpOkaWLxLcuYd8y5U3KsYS96kzQA7OhKkiSplSx0JUmS1EoWupIkSWolx+hOIzM22aRy7G3/tWPl2P9ZcOY4sqiWwyGzVlTe471rVlWOPeDEoyvHzhleXTn2w8d/pnLs/tW/DNz6it0rx2578iXVdyxJ0jRgR1eSBkBEvCoich1T9d++JEl2dCVpQFwBfKjHumcBBwPfnbJsJKkFLHQlaQBk5hUUxe4jRMSl5T9Pnap8JKkNHLogSQMsIvYCngHcAkzNTXAlqSUsdCVpsL2xnH82Mx2jK0nj4NAFSRpQETELOAJYA5xWcZuhHqv26FdektQUdnQlaXC9HNgS+G5m/q7mXCSpcezoStLgekM5/3TVDTJzQbflZad3fj+SkqSmsKMrSQMoIp4I7AfcDJxXczqS1EgWupI0mLwITZLWk0MXppGb3ln9r5ZXLDhpUnK4e80DleLe9/tDK+/zhvdWv8Zm+x9NzmNy3/L4N1WOvfyt1c/t/c9cXj2Jk6uHarBFxCbAkRQXoX225nQkqbHs6ErS4Dkc2Ao4z4vQJGniLHQlafCMXITmk9AkaT1Y6ErSAImIPYFn4kVokrTeHKMrSQMkM5cAUXcektQGdnQlSZLUSha6kiRJaiWHLkjSNLHXDnMYWrSw7jQkacrY0ZUkSVIrWehKkiSplSx0JUmS1EqO0W24VQufVjn2qrd8snLs6qx+d6MnnP/6yrE7n1EtbuaPhirvcybVYyfLTqddUzl26A3rjhnx4t1/VTn2yo03rhybq1ZVT0KSpIayoytJkqRWsqMrSdPE4luWMe+Ycydl38PezUHSALKjK0mSpFay0JUkSVIrWehKkiSplSx0JUmS1EoWupI0QCLiWRHxtYi4NSJWlfMfRMRf1Z2bJDWNd12QpAEREe8H/glYCnwHuBXYBtgbOBA4r7bkJKmBLHQlaQBExOEURe4PgZdk5n2j1m9YS2KS1GAOXZCkmkXEDOB4YAXwN6OLXIDMfGjKE5OkhrOj23C3PbV6k2d1rqkc+6Lrqt/8fbfXXVk5Nh9+uHJsk6x57NzKsbtvWP3xu79Zvk3l2Hzo7sqxGjj7ATsDZwN3R8RCYC/gAeCXmXlpnclJUlNZ6EpS/Z5Wzm8DLgOe3LkyIi4CXpaZd6xrRxEx1GPVHuuVoSQ1kEMXJKl+25bzNwGzgL8AtqDo6n4fOAD4aj2pSVJz2dGVpPptUM6DonM7Mh7oqoh4MXAt8OyI2Hddwxgyc0G35WWnd36/EpakJrCjK0n1GxlgfUNHkQtAZq6k6OoC7DOlWUlSw1noSlL9rinn9/RYP1IIz5r8VCSpPSx0Jal+FwEPA0+IiI26rN+rnA9PWUaS1AIWupJUs8xcCnwZmAN8oHNdRDwH+EtgGfC9qc9OkprLi9EkaTC8E3g68L6IOAD4JfA44MXAauD1mXlPfelJUvNY6ErSAMjM2yPi6cD7KYrbZwD3AecC/5KZP68zP0lqIgtdSRoQmXkXRWf3nXXnIkltYKE7gDaYPbty7NGv+Hrl2NPv3b5y7Ip/3qFy7IYP31o5tklu+sB+lWPf/NfnVo7dfMbGlWNXPNztuqQe1qyuHitJ0jTgxWiSJElqJTu6kjRN7LXDHIYWLaw7DUmaMnZ0JUmS1EoWupIkSWolC11JkiS1koWuJEmSWslCV5IkSa3kXRckaZpYfMsy5h1T/Z7P62PYuztIGgB2dCVJktRKFrqSJElqJYcuDKA1Kx+oHDu0fF7l2N02/UPl2FnXL60cm1ttVTk2Np1VOXYy/PbIeZVjP/+qkyrHLqj+VN9xuefTO1WO3YLfT04SkiQ1lB1dSRoAETEcEdljqv5bqiTpj+zoStLgWAac0GX58inOQ5JawUJXkgbHPZl5XN1JSFJbOHRBkiRJrWRHV5IGx8YRcQSwE3A/8CvgosxcXW9aktRMFrqSNDjmAmeMWnZjRLw6M39SR0KS1GQWupI0GD4PXAxcBdwH7AK8BXgD8N2I2Dczr1zXTiJiqMeqPfqVqCQ1hYWuJA2AzPzQqEWLgTdFxHLgXcBxwIunOi9JajILXUkabKdQFLoHVAnOzAXdlped3vl9zEuSBp53XZCkwXZ7Od+s1iwkqYHs6A6gfOjByrHDy7evHHvS9pdUjj3q4t9Ujv3Ryk0rxx4ya0Xl2KpmEJVj15B9P/5k2uKsn9edguq3bzm/odYsJKmB7OhKUs0i4kkRsXWX5Y8DTi5fnjm1WUlS89nRlaT6HQ4cExEXADdS3HVhV2AhsAlwHvDR+tKTpGay0JWk+l0A7A7sTTFUYTPgHuCnFPfVPSMzmzXuRpIGgIWuJNWsfBiED4SQpD5zjK4kSZJayUJXkiRJrWShK0mSpFZyjK4kTRN77TCHoUUL605DkqaMHV1JkiS1kh3dhvv91+dVjt3gPeP4vSbXVA59zqyV1fc7jqeYVbVBTM77kiRJzWZHV5IkSa1koStJkqRWcuiCJE0Ti29Zxrxjzp3UYwx7sZukAWJHV5IkSa1koStJkqRWstCVJElSK1noSpIkqZUsdCVpQEXEkRGR5fS6uvORpKax0JWkARQRjwVOApbXnYskNZWFriQNmIgI4PPAncApNacjSY3lfXQbbu6l91aO3fXHr64c++uDTptIOrV49q9eUjn2/m/NrRz76Cvurxz7qf/6j8qxO82cVTl26Rv2rRy7zamXVo7VwHsbcDBwYDmXJE2AHV1JGiARsSewCDgxMy+qOx9JajI7upI0ICJiJnAGcBPw3gnuY6jHqj0mmpckNZWFriQNjg8AewPPzMyVdScjSU1noStJAyAi9qHo4n4sMyc84DozF/TY/xAwf6L7laQmcoyuJNWsY8jCtcCxNacjSa1hoStJ9dsc2A3YE3ig4yERCXywjPlMueyEupKUpKZx6IIk1W8V8Nke6+ZTjNv9KXAN4H3kJKkiC11Jqll54VnXR/xGxHEUhe4XMrM5N7iWpAHg0AVJkiS1koWuJEmSWsmhCw2X/7O4euxdT5/ETPrrxocfqBy72XNvqB5L9djxOGnpgZVj/23uLyrHrtkoJpCN2iQzjwOOqzkNSWokO7qSJElqJQtdSZIktZJDFyRpmthrhzkMLVpYdxqSNGXs6EqSJKmVLHQlSZLUSha6kiRJaiULXUmSJLWSha4kSZJaybsuSNI0sfiWZcw75twpO96wd3iQVDM7upIkSWolO7oNd+//eUbl2Ote+snKsWvGkcO5K+ZUjj3+g0dUitvyqmXjyGDJOGKri5nV/3tsOuPBSclBkiRNnB1dSZIktZKFriRJklrJQleSBkBEHB8RP4qI30XEyoi4KyIuj4gPRsSj6s5PkprIQleSBsM7gM2A84ETgS8BDwPHAb+KiMfWl5okNZMXo0nSYJidmQ+MXhgRHwHeC7wHePOUZyVJDWZHV5IGQLcit/SVcv6EqcpFktrCQleSBtsLyvmvas1CkhrIoQuSNEAi4mhgc2AO8FTgmRRF7qKK2w/1WLVHXxKUpAax0JWkwXI0sF3H6+8Br8rMO2rKR5Iay0JXkgZIZs4FiIjtgP0oOrmXR8TzM/OyCtsv6La87PTO72eukjToLHQb7s4XrZiU/Z66bF7l2HP326Vy7Ox7fl4pbjyPIJ4sN79rn8qx3972pMqxX1m+beXYx3zv1sqxqytHqgky8zbgnIi4DLgW+CKwV71ZSVKzeDGaJA2wzPwtcDXwpIjYpu58JKlJLHQlafBtX85t3EvSOFjoSlLNImKPiJjbZfmM8oER2wKXZObdU5+dJDWXY3QlqX7PBf4tIi4CfgPcSXHnhWcDuwB/AF5fX3qS1EwWupJUvx8CpwL7A38ObAncT3ER2hnAJzLzrtqyk6SGstCVpJpl5mLgqLrzkKS2cYyuJEmSWslCV5IkSa3k0AVJmib22mEOQ4sW1p2GJE0ZO7qSJElqJTu6Dbfb3Dsqx24Q1X+vOeeo51Tf7z2XVY6t28oXVX+s7zff/K+VY2ewaeXYfz79ryvH7nj9JZVjJUnSn7KjK0mSpFay0JUkSVIrWehKkiSplRyjK0nTxOJbljHvmHOn/LjD3ulBUk3s6EqSJKmVLHQlSZLUSha6kiRJaiULXUmqWUQ8KiJeFxHnRMT1EbEyIpZFxE8j4rUR47gJtiTpj7wYTZLqdzjwKeBW4ALgJmA74CXAacDzIuLwzMz6UpSk5rHQlaT6XQu8EDg3M9eMLIyI9wK/BF5KUfR+rZ70JKmZLHQbbk1G5djVa39+rtPMe1ZVjq27xXTXa/atHPvFD3yscuxOM2dVjv3svTtWjn3svw9Vjq373GpqZOaPeyz/Q0ScAnwEOBALXUkaF8d9SdJge6icP1xrFpLUQBa6kjSgImIm8Lfly+/VmYskNZFDFyRpcC0C9gLOy8zvV9kgInqNjdmjb1lJUkPY0ZWkARQRbwPeBfwaOLLmdCSpkezoStKAiYijgBOBq4FDMvOuqttm5oIe+xwC5vcnQ0lqBju6kjRAIuLtwMnAYuCgzPxDvRlJUnNZ6ErSgIiIdwMfB66gKHJvrzcjSWo2C11JGgARcSzFxWdDFMMVltackiQ1nmN0JalmEfFK4B+B1cDFwNsiHvEwmOHMPH2KU5OkRrPQlaT67VzONwDe3iPmJ8DpU5GMJLWFhW7D3XH/5pOy32O/dkbl2CPOf2Pl2BkrNqgUd8C+V1Xe53mP/Y/KsWvYuHLsjQ8/UDn2q2/6y8qxM1ZdXjlW00NmHgccV3MaktQ6jtGVJElSK1noSpIkqZUsdCVJktRKjtGVpGlirx3mMLRoYd1pSNKUsaMrSZKkVrLQlSRJUitZ6EqSJKmVLHQlSZLUSl6MJknTxOJbljHvmHOn/LjDXgAnqSZ2dCVJktRKdnQbbs23HlU9eO/qoftsnJVjr33+KdV3PCmicuTda6o/1vcPqzerHLvhHfdXjl1dOVKSJK0PO7qSJElqJQtdSZIktZKFriQNgIh4WUScFBEXR8S9EZERcWbdeUlSkzlGV5IGw/uBPweWAzcDe9SbjiQ1nx1dSRoM7wB2A2YDf1dzLpLUCnZ0JWkAZOYFI/+OqH4nEUlSb3Z0JUmS1Ep2dCWpRSJiqMcqx/xKmnbs6EqSJKmV7OhKUotk5oJuy8tO7/wpTkeSamWh23DbnHpp5di9t3hL5dg3vvbblWPfMGe4cuypy+ZVijvlmmdV3mdE9ccVb3PyppVjN166snLsmquvrhwrSZKmhkMXJEmS1EoWupIkSWolC11JkiS1kmN0JWkARMRhwGHly7nlfN+IOL3899LMPHqK05KkRrPQlaTB8BTglaOW7VJOAL8FLHQlaRwcuiBJAyAzj8vMGGOaV3eOktQ0FrqSJElqJQtdSZIktZJjdCVpmthrhzkMLVpYdxqSNGUsdKeRx3zsksqx3/rYo6rHUj22qu2p/0lja+pOQJIkrReHLkiSJKmVLHQlSZLUSha6kiRJaiULXUmSJLWSF6NJ0jSx+JZlzDvm3Ek9xrB3dZA0QOzoSpIkqZUsdCVJktRKFrqSJElqJQtdSZIktZKFriQNiIjYMSI+FxG/j4hVETEcESdExFZ15yZJTeRdFyRpAETErsAlwLbAN4FfA/sAfw88NyL2z8w7a0xRkhrHjq4kDYZPUhS5b8vMwzLzmMw8GPg4sDvwkVqzk6QGstCVpJpFxC7AocAw8B+jVn8QuB84MiI2m+LUJKnRLHQlqX4Hl/MfZOaazhWZeR/wM2BT4BlTnZgkNZljdCWpfruX82t7rL+OouO7G/CjsXYUEUM9Vu0xsdQkqbns6EpS/eaU82U91o8s33LyU5Gk9rCjK0mDL8p5riswMxd03UHR6Z3fz6QkadDZ0ZWk+o10bOf0WD97VJwkqQILXUmq3zXlfLce659QznuN4ZUkdWGhK0n1u6CcHxoRf/J9OSK2APYHVgI/n+rEJKnJLHQlqWaZ+RvgB8A84KhRqz8EbAZ8MTPvn+LUJKnRvBhNkgbDmykeAfyJiDgEWAI8HTiIYsjC+2rMTZIayY6uJA2Asqv7VOB0igL3XcCuwCeAfTPzzvqyk6RmsqMrSQMiM38HvLruPCSpLezoSpIkqZUsdCVJktRKDl2QpGlirx3mMLRoYd1pSNKUsaMrSZKkVrLQlSRJUitZ6EqSJKmVLHQlSZLUSha6kiRJaiULXUmSJLWSha4kSZJayUJXkiRJrWShK0mSpFay0JUkSVIrWehKkiSplSx0JUmS1Eoz605AkjQl5i1ZsoQFCxbUnYckjcuSJUsA5k1kWwtdSZoeNl+5cuXqyy677Mq6Exkge5TzX9eaxWDxnDyS5+SRpvqczAPunciGFrqSND0sBshMW7qliBgCz0knz8kjeU4eqUnnxDG6kiRJaqUJd3TPX/PV6GcikiRJUj/Z0ZUkSVIrWehKkiSplSx0JUmS1EqRmXXnIEmSJPWdHV1JkiS1koWuJEmSWslCV5IkSa1koStJkqRWstCVJElSK1noSpIkqZUsdCVJktRKFrqSNMAiYseI+FxE/D4iVkXEcEScEBFbTfZ+ImK/iDgvIu6KiBUR8auIeHtEbLD+72zi1vecRMSjIuJ1EXFORFwfESsjYllE/DQiXhsRj/jZGBHzIiLHmM7q/zutrh+fk3KbXu/vD2Ns19bPyavW8TXPiFg9apuB/ZxExMsi4qSIuDgi7i3zOXOC+2rM9xMfGCFJAyoidgUuAbYFvgn8GtgHOAi4Btg/M++cjP1ExIuArwEPAF8G7gJeAOwOnJ2Zh/fhLY5bP85JRLwJ+BRwK3ABcBOwHfASYA7F+z48O35ARsQ84EbgSuAbXXa7ODPPXo+3NmF9/JwMA1sCJ3RZvTwzP9plmzZ/Tp4CHNZj9bOAg4FzM/P5HdvMY3A/J1cAfw4sB24G9gC+lJlHjHM/zfp+kplOTk5OTgM4Ad8HEnjrqOX/Xi4/ZTL2A8wGbgdWAU/tWL4JxQ+4BF7R1HNCUaC8AJgxavlciqI3gZeOWjevXH563Z+LSfycDAPD4zhuqz8n69j/peV+Xtigz8lBwBOAAA4s8zxzss9t3Z+T2k+8k5OTk9MjJ2CX8gfAjV0Ksi0oujL3A5v1ez/Aa8ptvtBlfweX637S1HOyjmO8tzzGSaOWD2QB089zMoFCd1p+ToC9yv3fDGzQhM9Jl/cwoUK3id9PHKMrSYPp4HL+g8xc07kiM+8DfgZsCjxjEvYzss33uuzvImAFsF9EbLyuN9Fn/TonY3monD/cY/32EfHGiHhvOf+z9ThWP/T7nGwcEUeU7+/vI+KgMcZQTtfPyRvL+Wczc3WPmEH7nPRL476fWOhK0mDavZxf22P9deV8t0nYT89tMvNhim7OTIruzlTq1znpKiJmAn9bvuz2QxngOcApwEfK+ZURcUFE7DSRY/ZBv8/JXOAMivd3AvBj4LqIePZ4jt3Wz0lEzAKOANYAp40ROmifk35p3PcTC11JGkxzyvmyHutHlm85Cfvp17H7bbLzWkTxZ+nzMvP7o9atAP4JWABsVU7PpriY7UDgRxGx2QSPuz76eU4+DxxCUexuBjwZ+DTFn+O/GxF/PonH7qfJzOvl5XbfzczfdVk/qJ+Tfmnc9xMLXUlqpijn63vrnInsp1/H7rcJ5xURbwPeRXEF+ZGj12fm7Zn5gcy8LDPvKaeLgEOBXwCPB1438dQnTeVzkpkfyswfZ+ZtmbkiMxdn5psoLjKaBRw3WceeYuuT1xvK+ae7rWzw56RfBu77iYWuJA2mkS7HnB7rZ4+K6+d++nXsfpuUvCLiKOBE4GrgoMy8q+q25Z9eR/6EfcB4jtsnU/G1OqWcj35/0+1z8kRgP4qL0M4bz7YD8Dnpl8Z9P7HQlaTBdE057zWO8AnlvNdYufXZT89tynGsO1NcrHXDOo7db/06J38UEW8HTgYWUxS5PR+MMIY7ynkdf5Lu+znp4vZyPvr9TZvPSanKRWhjqfNz0i+N+35ioStJg+mCcn5ojHpSV0RsAewPrAR+Pgn7+XE5f26X/R1AcVX1JZm5al1vos/6dU5Gtnk38HHgCooi9/axt+hp5ArzqS7ooM/npId9y/no9zctPifldptQDGlZA3x2gnnV+Tnpl8Z9P7HQlaQBlJm/AX5AcSHQUaNWf4iiK/TFzLwfICI2jIg9yqcWTXg/pbOBpcArIuKpIwvLH/YfLl9+asJvboL6dU7KdcdSXHw2BBySmUvHOnZEPD0iNuqy/GDgHeXLCT1OdX3065xExJMiYuvR+4+Ix1F0vOGR76/1n5MOh1NcWHZej4vQKPc1kJ+T8WrT9xMfASxJA6rLozaXAE+neMLRtcB+WT5qs+PRo7/NzHkT3U/HNodR/IB6ADiL4pGdL6R8ZCfw8qzhB0g/zklEvBI4HVgNnET3sYHDmXl6xzYXAk8CLqQYownwZ6y9R+ixmflhatCnc3IccAxFx+5G4D5gV2AhxROszgNenJkPjjr2YbT0czJqfxcDz6R4Etq3xzjuhQzu5+Qw1j7SeC7wlxTd5YvLZUsz8+gydh5t+X4yWU+icHJycnJa/wl4LMVtn24FHgR+S3Hh1Naj4uZRXLU8vD77GbXN/hQFzt0Uf478X4qu1Ab9en91nBOKuwfkOqYLR23zWuA7FE8PW07xONObgC8Dz2r654TiFlj/RXHXiXsoHpxxB3A+xb2FY7p9TjrW71mu/9263tMgf04qfO6HO2Jb8/3Ejq4kSZJayTG6kiRJaiULXUmSJLWSha4kSZJayUJXkiRJrWShK0mSpFay0JUkSVIrWehKkiSplSx0JUmS1EoWupIkSWolC11JkiS1koWuJEmSWslCV5IkSa1koStJkqRWstCVJElSK1noSpIkqZUsdCVJktRKFrqSJElqpf8PgBfbbg17ZwMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "The network we built isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
    "\n",
    "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
    "\n",
    "$$\n",
    "\\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
    "\n",
    "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backpropagation\n",
    "\n",
    "For single layer networks, gradient descent is simple to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks, although it's straightforward once you learn about it. \n",
    "\n",
    "This is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
    "\n",
    "<img src='assets/w1_backprop_graph.png' width=400px>\n",
    "\n",
    "In the forward pass through the network, our data and operations go from right to left here. To train the weights with gradient descent, we propagate the gradient of the cost backwards through the network. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial w_1} = \\frac{\\partial l_1}{\\partial w_1} \\frac{\\partial s}{\\partial l_1} \\frac{\\partial l_2}{\\partial s} \\frac{\\partial \\ell}{\\partial l_2}\n",
    "$$\n",
    "\n",
    "We update our weights using this gradient with some learning rate $\\alpha$. \n",
    "\n",
    "$$\n",
    "w^\\prime = w - \\alpha \\frac{\\partial \\ell}{\\partial w}\n",
    "$$\n",
    "\n",
    "The learning rate is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Autograd\n",
    "\n",
    "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0695, -0.1211],\n",
      "        [-2.5047, -0.3844]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "y = x**2\n",
    "print(y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[4.8291e-03, 1.4663e-02],\n",
      "        [6.2734e+00, 1.4778e-01]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we can see the operation that created `y`, a power operation `PowBackward0`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PowBackward0 object at 0x7fb3eb805b80>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.6102, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can check the gradients for `x` and `y` but they are empty currently."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "print(x.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0347, -0.0605],\n",
      "        [-1.2523, -0.1922]])\n",
      "tensor([[-0.0347, -0.0605],\n",
      "        [-1.2523, -0.1922]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the cost, then, go backwards to calculate the gradients with respect to the cost. Once we have the gradients we can make a gradient descent step. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size  = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('fc3',nn.Linear(hidden_sizes[1],output_size)),\n",
    "          ('output', nn.Softmax(dim=1))]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the network!\n",
    "\n",
    "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
    "\n",
    "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "print('Initial weights - ', model.fc1.weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model.fc1.weight.grad)\n",
    "optimizer.step()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0180, -0.0099,  0.0294,  ..., -0.0227,  0.0267, -0.0048],\n",
      "        [ 0.0052,  0.0146, -0.0180,  ..., -0.0296,  0.0202, -0.0105],\n",
      "        [-0.0295, -0.0299, -0.0053,  ..., -0.0050, -0.0162, -0.0205],\n",
      "        ...,\n",
      "        [ 0.0023, -0.0217, -0.0038,  ...,  0.0294,  0.0035, -0.0242],\n",
      "        [ 0.0300, -0.0056, -0.0036,  ...,  0.0174, -0.0250, -0.0181],\n",
      "        [ 0.0168,  0.0169, -0.0129,  ..., -0.0118,  0.0004,  0.0337]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],\n",
      "        ...,\n",
      "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
      "        [-0.0026, -0.0026, -0.0026,  ..., -0.0026, -0.0026, -0.0026],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "print('Updated weights - ', model.fc1.weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0179, -0.0098,  0.0294,  ..., -0.0226,  0.0267, -0.0048],\n",
      "        [ 0.0052,  0.0146, -0.0180,  ..., -0.0296,  0.0202, -0.0105],\n",
      "        [-0.0295, -0.0300, -0.0053,  ..., -0.0050, -0.0162, -0.0206],\n",
      "        ...,\n",
      "        [ 0.0023, -0.0217, -0.0038,  ...,  0.0294,  0.0035, -0.0242],\n",
      "        [ 0.0300, -0.0056, -0.0036,  ...,  0.0174, -0.0249, -0.0181],\n",
      "        [ 0.0168,  0.0169, -0.0129,  ..., -0.0118,  0.0004,  0.0337]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training for real\n",
    "\n",
    "Now we'll put this algorithm into a loop so we can go through all the images. This is fairly straightforward. We'll loop through the mini-batches in our dataset, pass the data through the network to calculate the losses, get the gradients, then run the optimizer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.03)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "epochs = 10\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {e+1}/{epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels) # 2) Compute loss\n",
    "        loss.backward()                  # 3) Backward pass\n",
    "        optimizer.step()                 # 4) Update model\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/10\n",
      "\tIteration: 0\t Loss: 0.0577\n",
      "\tIteration: 40\t Loss: 2.1925\n",
      "\tIteration: 80\t Loss: 1.7608\n",
      "\tIteration: 120\t Loss: 1.2008\n",
      "\tIteration: 160\t Loss: 0.8582\n",
      "\tIteration: 200\t Loss: 0.6846\n",
      "\tIteration: 240\t Loss: 0.5902\n",
      "\tIteration: 280\t Loss: 0.5345\n",
      "\tIteration: 320\t Loss: 0.4593\n",
      "\tIteration: 360\t Loss: 0.5220\n",
      "\tIteration: 400\t Loss: 0.4324\n",
      "\tIteration: 440\t Loss: 0.4247\n",
      "\tIteration: 480\t Loss: 0.4304\n",
      "\tIteration: 520\t Loss: 0.4007\n",
      "\tIteration: 560\t Loss: 0.3790\n",
      "\tIteration: 600\t Loss: 0.3906\n",
      "\tIteration: 640\t Loss: 0.3676\n",
      "\tIteration: 680\t Loss: 0.3878\n",
      "\tIteration: 720\t Loss: 0.3584\n",
      "\tIteration: 760\t Loss: 0.3502\n",
      "\tIteration: 800\t Loss: 0.3615\n",
      "\tIteration: 840\t Loss: 0.3457\n",
      "\tIteration: 880\t Loss: 0.3355\n",
      "\tIteration: 920\t Loss: 0.3282\n",
      "Epoch: 2/10\n",
      "\tIteration: 0\t Loss: 0.0077\n",
      "\tIteration: 40\t Loss: 0.3381\n",
      "\tIteration: 80\t Loss: 0.2822\n",
      "\tIteration: 120\t Loss: 0.3029\n",
      "\tIteration: 160\t Loss: 0.3256\n",
      "\tIteration: 200\t Loss: 0.3141\n",
      "\tIteration: 240\t Loss: 0.2894\n",
      "\tIteration: 280\t Loss: 0.2899\n",
      "\tIteration: 320\t Loss: 0.3108\n",
      "\tIteration: 360\t Loss: 0.2938\n",
      "\tIteration: 400\t Loss: 0.2946\n",
      "\tIteration: 440\t Loss: 0.2999\n",
      "\tIteration: 480\t Loss: 0.2984\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1h/x7tmv9xd1bsclx868ql32nf40000gn/T/ipykernel_48978/3431744169.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 2) Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# 3) Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_env/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_env/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/deep_env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the network trained, we can check out it's predictions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model1.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "# ps = F.softmax(logits, dim=1)\n",
    "view_classify(img.view(1, 28, 28),logits)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now our network is brilliant. It can accurately predict the digits in our images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">MNIST Clasification: Exercise</h2>\n",
    "<div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
    "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
    "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 400 units in the first hidden layer, 200 units in the second layer, and 100 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
    "<div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## TODO: Your network here\n",
    "input_dim = 784\n",
    "hidden_dims = [400,200,100]\n",
    "output = 10\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('clf1',nn.Linear(input_dim,hidden_dims[0])),\n",
    "    ('act1',nn.ReLU()),\n",
    "    ('clf2',nn.Linear(hidden_dims[0],hidden_dims[1])),\n",
    "    ('act2',nn.ReLU()),\n",
    "    ('clf3',nn.Linear(hidden_dims[1],hidden_dims[2])),\n",
    "    ('act3',nn.ReLU()),\n",
    "    ('clf4',nn.Linear(hidden_dims[2],output)),\n",
    "    ('output',nn.Softmax(dim=1))\n",
    "]))\n",
    "\n",
    "model_logit = nn.Sequential(OrderedDict([\n",
    "    ('clf1',nn.Linear(input_dim,hidden_dims[0])),\n",
    "    ('act1',nn.ReLU()),\n",
    "    ('clf2',nn.Linear(hidden_dims[0],hidden_dims[1])),\n",
    "    ('act2',nn.ReLU()),\n",
    "    ('clf3',nn.Linear(hidden_dims[1],hidden_dims[2])),\n",
    "    ('act3',nn.ReLU()),\n",
    "    ('logit',nn.Linear(hidden_dims[2],output)),\n",
    "]))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5),(0.5))])\n",
    "trainset = datasets.MNIST('MNIST_sets/',download=True,train=True,transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)\n",
    "testset = datasets.MNIST('MINST_sets/',download=True,train=False,transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=64,shuffle=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
    "# def trainer(model,optimizer,loss,epochs,lr):\n",
    "#     print_interval = 50\n",
    "#     losses = 0\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f'running epoch {epoch+1} out of epochs')\n",
    "#         for i, (images,labels) in enumerate(iter(trainloader)):\n",
    "#             images.resize_(images.size()[0],784)\n",
    "#             optimizer.zero_grad()\n",
    "#             y_h = model(images)\n",
    "#             loss_values = loss(y_h,labels)\n",
    "#             loss_values.backward()\n",
    "#             optimizer.step()\n",
    "#             losses+=loss_values.item()\n",
    "\n",
    "#             if i % print_interval==0:\n",
    "#                 print(f'\\t {i} iteration loss: \\t {losses/print_interval}')\n",
    "#                 losses=0\n",
    "\n",
    "# trainer(model,optimizer,loss,10,0.001)     \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell with your model to make sure it works\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "ps = nn.Softmax()\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
    "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
    "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
    "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
    "</a></p>\n",
    "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
    "<div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "## TODO:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
    "def trainer(model,optimizer,loss,epochs,lr):\n",
    "    optimizer = optim.SGD(model.parameters(),lr=lr)\n",
    "    print_interval = 50\n",
    "    losses = 0\n",
    "    losses_eval = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(f'running epoch {epoch+1} out of epochs')\n",
    "        for i, (images,labels) in enumerate(iter(trainloader)):\n",
    "            images.resize_(images.size()[0],784)\n",
    "            optimizer.zero_grad()\n",
    "            y_h = model(images)\n",
    "            loss_values = loss(y_h,labels)\n",
    "            loss_values.backward()\n",
    "            optimizer.step()\n",
    "            losses+=loss_values.item()\n",
    "\n",
    "            if i % print_interval==0:\n",
    "                print(f'\\t {i} iteration loss: \\t {losses/print_interval}')\n",
    "                losses=0\n",
    "\n",
    "        model.eval()\n",
    "        for j,(imgs,lbls) in enumerate(iter(testloader)):\n",
    "\n",
    "            imgs.resize_(imgs.size()[0],784)\n",
    "            with torch.no_grad():\n",
    "                y_h_eval = model(imgs)\n",
    "\n",
    "                loss_values_eval = loss(y_h_eval,lbls)\n",
    "                losses_eval += loss_values_eval.item()\n",
    "                \n",
    "            if j%print_interval==0:\n",
    "                print(f'\\t\\t {j} iteration evalation loss\\t {losses_eval/print_interval}')\n",
    "                losses_eval =0\n",
    "                \n",
    "        model.train()\n",
    "        \n",
    "\n",
    "\n",
    "trainer(model_logit,optimizer,loss,10,0.03)\n",
    "# trainer(model,optimizer,loss,10,0.001)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
    "images, labels = next(iter(testloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "ps = F.softmax(ps, dim=1)\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
    "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
    "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
    "<div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## TODO: Your training loop here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "## TODO:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.03)\n",
    "def trainer(model,optimizer,loss,epochs,lr):\n",
    "    optimizer = optim.SGD(model.parameters(),lr=lr)\n",
    "    flag=False\n",
    "    print_interval = 50\n",
    "    monitor = []\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        print(f'running epoch {epoch+1} out of {epochs} epochs')\n",
    "        #training step\n",
    "        for i, (images,labels) in enumerate(iter(trainloader)): #iterating over trainloader images\n",
    "            images.resize_(images.size()[0],784) # [64,1,28,28] -> [64,784]\n",
    "            optimizer.zero_grad() # setting  grad =0, to prevent grad accumualtion\n",
    "            y_h = model(images) # forward pass\n",
    "            loss_values = loss(y_h,labels) # loss calc\n",
    "            loss_values.backward() # backprop\n",
    "            optimizer.step() #modification of weights with weight gradient calculated with help of backprop\n",
    "            losses.append(loss_values.item()) # appending losses, to calc mean loss for per epoch later\n",
    "        print(f'train average loss:\\t {torch.tensor(losses).mean()}') # printing average loss per epoch\n",
    "\n",
    "\n",
    "        model.eval() #eval mode on\n",
    "        losses_eval = []\n",
    "        #validation step\n",
    "        for j,(imgs,lbls) in enumerate(iter(testloader)):\n",
    "            imgs.resize_(imgs.size()[0],784)\n",
    "            with torch.no_grad(): #we are not training , not modifying weight, so we dont need to store grad of weights to calc graph\n",
    "                y_h_eval = model(imgs)\n",
    "                loss_values_eval = loss(y_h_eval,lbls)\n",
    "                losses_eval.append(loss_values_eval.item())\n",
    "            \n",
    "        monitor.append(torch.tensor(losses_eval).mean())#storing mean loss per epoch, later to check whether it's decreasing in 2 epochs or not\n",
    "        print(f'validation loss:\\t {monitor[epoch]}')\n",
    "        if epoch>=2:\n",
    "            if not monitor[epoch]<monitor[epoch-1] and not monitor[epoch-1]<monitor[epoch-2]:\n",
    "                print('validation loss is not decreasing for 2 epochs, so we stop training.')\n",
    "                flag = True\n",
    "                break\n",
    "            if flag == True:\n",
    "                break\n",
    "        if flag==True:\n",
    "            break\n",
    "        \n",
    "        model.train() #back to training mode\n",
    "\n",
    "    return model\n",
    "        \n",
    "\n",
    "\n",
    "trainer(model,optimizer,loss,10,0.05)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running epoch 1 out of 10 epochs\n",
      "train average loss:\t 0.24732787907123566\n",
      "validation loss:\t 0.20781075954437256\n",
      "running epoch 2 out of 10 epochs\n",
      "train average loss:\t 0.17653657495975494\n",
      "validation loss:\t 0.18226997554302216\n",
      "running epoch 3 out of 10 epochs\n",
      "train average loss:\t 0.14018787443637848\n",
      "validation loss:\t 0.15147140622138977\n",
      "running epoch 4 out of 10 epochs\n",
      "train average loss:\t 0.11682385206222534\n",
      "validation loss:\t 0.10594619810581207\n",
      "running epoch 5 out of 10 epochs\n",
      "train average loss:\t 0.09933100640773773\n",
      "validation loss:\t 0.15372927486896515\n",
      "running epoch 6 out of 10 epochs\n",
      "train average loss:\t 0.0855698436498642\n",
      "validation loss:\t 0.09470247477293015\n",
      "running epoch 7 out of 10 epochs\n",
      "train average loss:\t 0.07683069258928299\n",
      "validation loss:\t 0.09412101656198502\n",
      "running epoch 8 out of 10 epochs\n",
      "train average loss:\t 0.06840063631534576\n",
      "validation loss:\t 0.08188733458518982\n",
      "running epoch 9 out of 10 epochs\n",
      "train average loss:\t 0.0627189427614212\n",
      "validation loss:\t 0.08494671434164047\n",
      "running epoch 10 out of 10 epochs\n",
      "train average loss:\t 0.056296031922101974\n",
      "validation loss:\t 0.07591456174850464\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (logits): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "images, labels = next(iter(testloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model_logit.forward(images[0,:])\n",
    "ps = F.softmax(ps, dim=1)\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 349,
       "height": 195
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('deep_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "7b884b91808f249adbbbc046303483b453e9d806c558c4e2b2582ccec117f281"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}