{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "source": [
    "########################## EDA\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "########################## Preprecessing\n",
    "#import spacy\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "########################## Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "from sklearn.naive_bayes  import BernoulliNB\n",
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from xgboost              import XGBClassifier\n",
    "\n",
    "########################## Machine Learning Evaluation\n",
    "from sklearn.metrics         import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "source": [
    "df= pd.read_csv(\"imdb.csv\")\n",
    "\n",
    "df_train = df.sample(frac = 0.8)\n",
    "  \n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "print(\"Number of documents in training data: %d\" % len(df_train))\n",
    "print(\"Number of documents in validation data: %d\" % len(df_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of documents in training data: 20000\n",
      "Number of documents in validation data: 5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "source": [
    "df_train['review'] = df_train['review'].apply(lambda x: x.lower())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "source": [
    "import re\n",
    "# # df_train['review'] = df_train['review'].apply(lambda x: re.findall(r\"[\\w']+\",x))\n",
    "\n",
    "\n",
    "# def cleaner(x):\n",
    "#     for val in x:\n",
    "#         val=val.strip()\n",
    "#         # print(val)\n",
    "#         if val.isalpha():\n",
    "#             # print(val)\n",
    "#             # print(val)\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(val)\n",
    "#             # x.remove(val)\n",
    "#     return x\n",
    "# # df_train['review'] = df_train['review'].apply(cleaner)\n",
    "# # df_train['review'] = df_train['review'].apply(lambda x: \" \".join(x))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "source": [
    "\n",
    "X_train = df_train['review'].apply(lambda x: re.sub('[^a-zA-Z]+', ' ', x))\n",
    "X_test = df_valid['review'].apply(lambda x: re.sub('[^a-zA-Z]+', ' ', x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA\n",
    "###Â Target"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "source": [
    "y_train = df_train['sentiment']\n",
    "y_test = df_valid['sentiment']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "source": [
    "sb.countplot(df_train['sentiment'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/saidalikhonalikhonov/opt/anaconda3/envs/new_env/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "metadata": {},
     "execution_count": 418
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAARpElEQVR4nO3df8xeZX3H8ffHVhF/dMJ4YNiiZbPTFZw/aBA1W5yY0blpmRFXE0d1JF0IOnW/Atsi20yjZkwnRliIIkWN2KAb1QQ3UnXuB8IelK0WxujEQaXSok7RTbT43R/39eht+7Tc7dXnvvv4vF/JnXPO91zXOddpnuaT8+M+d6oKSZIO1SMmPQBJ0vxmkEiSuhgkkqQuBokkqYtBIknqsnjSAxi34447rpYvXz7pYUjSvHLLLbfcX1VTs61bcEGyfPlypqenJz0MSZpXkvz3/tZ5aUuS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdZmzIElyZZJdSb4wVDs2yQ1J7mzTY4bWXZRke5I7kpw1VD8tyda27tIkafWjkny41W9KsnyujkWStH9zeUZyFbB6r9qFwJaqWgFsacskWQmsBU5pfS5Lsqj1uRxYD6xon5ltngd8vaqeArwDeNucHYkkab/mLEiq6jPA1/YqrwE2tvmNwNlD9Wuq6sGqugvYDpye5ERgSVXdWIMfTrl6rz4z27oWOHPmbEWSND7j/mb7CVW1E6CqdiY5vtWXAp8darej1b7X5veuz/S5p21rT5JvAD8J3L/3TpOsZ3BWw5Oe9KTugzjtD67u3oZ+/NzyF+dOegjc/edPn/QQdAR60pu2zun2j5Sb7bOdSdQB6gfqs2+x6oqqWlVVq6amZn1VjCTpEI07SO5rl6to012tvgM4aajdMuDeVl82S/1H+iRZDPwE+15KkyTNsXEHyWZgXZtfB1w3VF/bnsQ6mcFN9ZvbZbAHkpzR7n+cu1efmW29HPhk+QP0kjR2c3aPJMmHgBcAxyXZAVwMvBXYlOQ84G7gHICq2pZkE3AbsAe4oKoeaps6n8ETYEcD17cPwHuB9yfZzuBMZO1cHYskaf/mLEiq6pX7WXXmftpvADbMUp8GTp2l/h1aEEmSJudIudkuSZqnDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1mUiQJHljkm1JvpDkQ0keneTYJDckubNNjxlqf1GS7UnuSHLWUP20JFvbukuTZBLHI0kL2diDJMlS4HeAVVV1KrAIWAtcCGypqhXAlrZMkpVt/SnAauCyJIva5i4H1gMr2mf1GA9FksTkLm0tBo5Oshh4DHAvsAbY2NZvBM5u82uAa6rqwaq6C9gOnJ7kRGBJVd1YVQVcPdRHkjQmYw+SqvoycAlwN7AT+EZV/T1wQlXtbG12Ase3LkuBe4Y2saPVlrb5vev7SLI+yXSS6d27dx/Ow5GkBW8Sl7aOYXCWcTLwROCxSV51oC6z1OoA9X2LVVdU1aqqWjU1NXWwQ5YkHcAkLm29CLirqnZX1feAjwLPA+5rl6to012t/Q7gpKH+yxhcCtvR5veuS5LGaBJBcjdwRpLHtKeszgRuBzYD61qbdcB1bX4zsDbJUUlOZnBT/eZ2+euBJGe07Zw71EeSNCaLx73DqropybXA54A9wOeBK4DHAZuSnMcgbM5p7bcl2QTc1tpfUFUPtc2dD1wFHA1c3z6SpDEae5AAVNXFwMV7lR9kcHYyW/sNwIZZ6tPAqYd9gJKkkfnNdklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVKXiQRJkickuTbJfyS5Pclzkxyb5IYkd7bpMUPtL0qyPckdSc4aqp+WZGtbd2mSTOJ4JGkhm9QZyTuBT1TV04BnALcDFwJbqmoFsKUtk2QlsBY4BVgNXJZkUdvO5cB6YEX7rB7nQUiSJhAkSZYAvwi8F6CqvltV/wOsATa2ZhuBs9v8GuCaqnqwqu4CtgOnJzkRWFJVN1ZVAVcP9ZEkjckkzkh+GtgNvC/J55O8J8ljgROqaidAmx7f2i8F7hnqv6PVlrb5vev7SLI+yXSS6d27dx/eo5GkBW4SQbIYeDZweVU9C/g27TLWfsx236MOUN+3WHVFVa2qqlVTU1MHO15J0gFMIkh2ADuq6qa2fC2DYLmvXa6iTXcNtT9pqP8y4N5WXzZLXZI0RmMPkqr6CnBPkqe20pnAbcBmYF2rrQOua/ObgbVJjkpyMoOb6je3y18PJDmjPa117lAfSdKYLB6lUZItVXXmw9UOwuuADyZ5FPBF4DUMQm1TkvOAu4FzAKpqW5JNDMJmD3BBVT3UtnM+cBVwNHB9+0iSxuiAQZLk0cBjgOPa9zpm7kssAZ54qDutqluBVbOsmjWYqmoDsGGW+jRw6qGOQ5LU7+HOSH4beAOD0LiFHwbJN4F3z92wJEnzxQGDpKreCbwzyeuq6l1jGpMkaR4Z6R5JVb0ryfOA5cN9qurqORqXJGmeGPVm+/uBnwFuBWZudM98m1yStICNFCQMboyvbK8ikSTpB0b9HskXgJ+ay4FIkuanUc9IjgNuS3Iz8OBMsapeOiejkiTNG6MGyZ/O5SAkSfPXqE9t/cNcD0SSND+N+tTWA/zwzbqPAh4JfLuqlszVwCRJ88OoZySPH15OcjZw+lwMSJI0vxzS23+r6m+BFx7eoUiS5qNRL229bGjxEQy+V+J3SiRJIz+19ZKh+T3Alxj8lrokaYEb9R7Ja+Z6IJKk+WmkeyRJliX5myS7ktyX5CNJlj18T0nSj7tRb7a/j8FP3j4RWAp8rNUkSQvcqEEyVVXvq6o97XMVMDWH45IkzROjBsn9SV6VZFH7vAr46lwOTJI0P4waJL8FvAL4CrATeDngDXhJ0siP/74ZWFdVXwdIcixwCYOAkSQtYKOekfz8TIgAVNXXgGfNzZAkSfPJqEHyiCTHzCy0M5JRz2YkST/GRg2DvwT+Jcm1DF6N8gpgw5yNSpI0b4z6zfark0wzeFFjgJdV1W1zOjJJ0rww8uWpFhyGhyTpRxzSa+QlSZphkEiSuhgkkqQuBokkqYtBIknqYpBIkrpMLEjaW4Q/n+TjbfnYJDckubNNh79Jf1GS7UnuSHLWUP20JFvbukuTZBLHIkkL2STPSF4P3D60fCGwpapWAFvaMklWAmuBU4DVwGVJFrU+lwPrgRXts3o8Q5ckzZhIkLSf6f1V4D1D5TXAxja/ETh7qH5NVT1YVXcB24HTk5wILKmqG6uqgKuH+kiSxmRSZyR/Bfwh8P2h2glVtROgTY9v9aXAPUPtdrTa0ja/d30fSdYnmU4yvXv37sNyAJKkgbEHSZJfA3ZV1S2jdpmlVgeo71usuqKqVlXVqqkpfyFYkg6nSbwK/vnAS5O8GHg0sCTJB4D7kpxYVTvbZatdrf0O4KSh/suAe1t92Sx1SdIYjf2MpKouqqplVbWcwU30T1bVq4DNwLrWbB1wXZvfDKxNclSSkxncVL+5Xf56IMkZ7Wmtc4f6SJLG5Ej6caq3ApuSnAfcDZwDUFXbkmxi8ObhPcAFVfVQ63M+cBVwNHB9+0iSxmiiQVJVnwY+3ea/Cpy5n3YbmOWHtKpqGjh17kYoSXo4frNdktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVKXsQdJkpOSfCrJ7Um2JXl9qx+b5IYkd7bpMUN9LkqyPckdSc4aqp+WZGtbd2mSjPt4JGmhm8QZyR7g96rq54AzgAuSrAQuBLZU1QpgS1umrVsLnAKsBi5Lsqht63JgPbCifVaP80AkSRMIkqraWVWfa/MPALcDS4E1wMbWbCNwdptfA1xTVQ9W1V3AduD0JCcCS6rqxqoq4OqhPpKkMZnoPZIky4FnATcBJ1TVThiEDXB8a7YUuGeo245WW9rm967Ptp/1SaaTTO/evfuwHoMkLXQTC5IkjwM+Aryhqr55oKaz1OoA9X2LVVdU1aqqWjU1NXXwg5Uk7ddEgiTJIxmEyAer6qOtfF+7XEWb7mr1HcBJQ92XAfe2+rJZ6pKkMZrEU1sB3gvcXlVvH1q1GVjX5tcB1w3V1yY5KsnJDG6q39wufz2Q5Iy2zXOH+kiSxmTxBPb5fOA3ga1Jbm21PwLeCmxKch5wN3AOQFVtS7IJuI3BE18XVNVDrd/5wFXA0cD17SNJGqOxB0lV/ROz398AOHM/fTYAG2apTwOnHr7RSZIOlt9slyR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHUxSCRJXQwSSVIXg0SS1MUgkSR1MUgkSV0MEklSF4NEktTFIJEkdTFIJEldDBJJUheDRJLUxSCRJHWZ90GSZHWSO5JsT3LhpMcjSQvNvA6SJIuAdwO/AqwEXplk5WRHJUkLy7wOEuB0YHtVfbGqvgtcA6yZ8JgkaUFZPOkBdFoK3DO0vAN4zt6NkqwH1rfFbyW5YwxjWyiOA+6f9CCOBLlk3aSHoB/l3+aMi3M4tvLk/a2Y70Ey279O7VOougK4Yu6Hs/Akma6qVZMeh7Q3/zbHZ75f2toBnDS0vAy4d0JjkaQFab4Hyb8CK5KcnORRwFpg84THJEkLyry+tFVVe5K8Fvg7YBFwZVVtm/CwFhovGepI5d/mmKRqn1sKkiSNbL5f2pIkTZhBIknqYpDokPhqGh2pklyZZFeSL0x6LAuFQaKD5qtpdIS7Clg96UEsJAaJDoWvptERq6o+A3xt0uNYSAwSHYrZXk2zdEJjkTRhBokOxUivppG0MBgkOhS+mkbSDxgkOhS+mkbSDxgkOmhVtQeYeTXN7cAmX02jI0WSDwE3Ak9NsiPJeZMe0487X5EiSeriGYkkqYtBIknqYpBIkroYJJKkLgaJJKmLQSKNUZJnJnnx0PJL5/rtyUlekOR5c7kPLWwGiTRezwR+ECRVtbmq3jrH+3wBYJBozvg9EmlESR4LbGLwSphFwJuB7cDbgccB9wOvrqqdST4N3AT8EvAE4Ly2vB04Gvgy8JY2v6qqXpvkKuD/gKcBTwZeA6wDngvcVFWvbuP4ZeDPgKOA/wJeU1XfSvIlYCPwEuCRwDnAd4DPAg8Bu4HXVdU/zsE/jxYwz0ik0a0G7q2qZ1TVqcAngHcBL6+q04ArgQ1D7RdX1enAG4CL2yv33wR8uKqeWVUfnmUfxwAvBN4IfAx4B3AK8PR2Wew44E+AF1XVs4Fp4HeH+t/f6pcDv19VXwL+GnhH26chosNu8aQHIM0jW4FLkrwN+DjwdeBU4IYkMDhL2TnU/qNteguwfMR9fKyqKslW4L6q2gqQZFvbxjIGPyb2z22fj2LwOpDZ9vmygzg26ZAZJNKIquo/k5zG4B7HW4AbgG1V9dz9dHmwTR9i9P9rM32+PzQ/s7y4beuGqnrlYdyn1MVLW9KIkjwR+N+q+gBwCfAcYCrJc9v6RyY55WE28wDw+I5hfBZ4fpKntH0+JsnPzvE+pQMySKTRPR24OcmtwB8zuN/xcuBtSf4NuJWHfzrqU8DKJLcm+Y2DHUBV7QZeDXwoyb8zCJanPUy3jwG/3vb5Cwe7T+nh+NSWJKmLZySSpC4GiSSpi0EiSepikEiSuhgkkqQuBokkqYtBIknq8v+6H5lRr2E6cAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "source": [
    "# positive = df[df['sentiment']==0]['review']\n",
    "# negative = df[df['sentiment']==1]['review']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "source": [
    "# %%time\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[26, 8])\n",
    "\n",
    "# wordcloud1 = WordCloud( background_color='white',\n",
    "#                         width=600,\n",
    "#                         height=400).generate(\" \".join(positive))\n",
    "# ax1.imshow(wordcloud1)\n",
    "# ax1.axis('off')\n",
    "# ax1.set_title('Positive', fontsize=40);\n",
    "\n",
    "# wordcloud2 = WordCloud( background_color='white',\n",
    "#                         width=600,\n",
    "#                         height=400).generate(\" \".join(negative))\n",
    "# ax2.imshow(wordcloud2)\n",
    "# ax2.axis('off')\n",
    "# ax2.set_title('Negative',fontsize=40);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we start with any NLP project we need to pre-process the data to get it all in a consistent format.We need to clean, tokenize and convert our data into a matrix. Some of the basic text pre-processing techniques includes:\n",
    "\n",
    "- Make text all **lower case** or **upper case** so that the algorithm does not treat the same words in different cases as different\n",
    "- **Removing Noise** i.e everything that isnât in a standard number or letter i.e Punctuation, Numerical values, common non-sensical text (/n)\n",
    "- **Tokenization**: Tokenization is just the term used to describe the process of converting the normal text strings into a list of tokens i.e words that we actually want. Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings.\n",
    "- **Stopword Removal**: Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words\n",
    "\n",
    "### More data cleaning steps after tokenization:\n",
    "- **Stemming**: Stemming is the process of reducing inflected (or sometimes derived) words to their stem, base or root formâââgenerally a written word form. Example if we were to stem the following words: âStemsâ, âStemmingâ, âStemmedâ, âand Stemtizationâ, the result would be a single word âstemâ.\n",
    "- **Lemmatization**: A slight variant of stemming is lemmatization. The major difference between these is, that, stemming can often create non-existent words, whereas lemmas are actual words. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma. Examples of Lemmatization are that ârunâ is a base form for words like ârunningâ or âranâ or that the word âbetterâ and âgoodâ are in the same lemma so they are considered the same.\n",
    "- **Parts of speech** tagging\n",
    "- Create **bi-grams** or tri-grams And more...\n",
    "\n",
    "However, it is not necessary that you would need to use all these steps. The usage depends on your problem at hand. Sometimes removal of stop words helps while at other times, this might not help.Here is a nice table taken from the blog titled: [All you need to know about Text Preprocessing for Machine Learning & NLP](https://kavita-ganesan.com/text-preprocessing-tutorial) that summarizes how much preprocessing you should be performing on your text data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center> Toy Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "source": [
    "texts = [\n",
    "    'Hello this is an sentence',\n",
    "    'Hello this is another sentence',\n",
    "    'Hello Hello Hello, this is mellow'\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "source": [
    "conter = CountVectorizer(ngram_range=(1,2))\n",
    "df = conter.fit_transform(texts)\n",
    "print(df.toarray())\n",
    "conter.get_feature_names()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 1 0 0 1 0 1 1 1 0 0 0 1 1 1]\n",
      " [0 0 1 1 1 0 1 1 0 1 0 0 1 1 1]\n",
      " [0 0 0 0 3 2 1 1 0 0 1 1 0 1 1]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['an',\n",
       " 'an sentence',\n",
       " 'another',\n",
       " 'another sentence',\n",
       " 'hello',\n",
       " 'hello hello',\n",
       " 'hello this',\n",
       " 'is',\n",
       " 'is an',\n",
       " 'is another',\n",
       " 'is mellow',\n",
       " 'mellow',\n",
       " 'sentence',\n",
       " 'this',\n",
       " 'this is']"
      ]
     },
     "metadata": {},
     "execution_count": 422
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bag Of Words (BOW)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "source": [
    "\n",
    "count_vec = CountVectorizer(ngram_range=(1,2))\n",
    "# create a CountVectorizer instance\n",
    "# fit tranform the text with it\n",
    "# get the features+\n",
    "\n",
    "bow = 0\n",
    "texts_bow = count_vec.fit_transform(texts)\n",
    "tokens = count_vec.get_feature_names()\n",
    "\n",
    "pd.DataFrame(data=texts_bow.toarray(), index=['Text 1', 'Text 2', \"Text 3\"], columns=tokens)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>an sentence</th>\n",
       "      <th>another</th>\n",
       "      <th>another sentence</th>\n",
       "      <th>hello</th>\n",
       "      <th>hello hello</th>\n",
       "      <th>hello this</th>\n",
       "      <th>is</th>\n",
       "      <th>is an</th>\n",
       "      <th>is another</th>\n",
       "      <th>is mellow</th>\n",
       "      <th>mellow</th>\n",
       "      <th>sentence</th>\n",
       "      <th>this</th>\n",
       "      <th>this is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        an  an sentence  another  another sentence  hello  hello hello  \\\n",
       "Text 1   1            1        0                 0      1            0   \n",
       "Text 2   0            0        1                 1      1            0   \n",
       "Text 3   0            0        0                 0      3            2   \n",
       "\n",
       "        hello this  is  is an  is another  is mellow  mellow  sentence  this  \\\n",
       "Text 1           1   1      1           0          0       0         1     1   \n",
       "Text 2           1   1      0           1          0       0         1     1   \n",
       "Text 3           1   1      0           0          1       1         0     1   \n",
       "\n",
       "        this is  \n",
       "Text 1        1  \n",
       "Text 2        1  \n",
       "Text 3        1  "
      ]
     },
     "metadata": {},
     "execution_count": 423
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bag Of Words (BOW) + ngram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "source": [
    "#do the same approach but using a range in the count vectorizer\n",
    "pd.DataFrame(data=texts_bow.toarray(), index=['Text 1', 'Text 2', \"Text 3\"], columns=tokens)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>an sentence</th>\n",
       "      <th>another</th>\n",
       "      <th>another sentence</th>\n",
       "      <th>hello</th>\n",
       "      <th>hello hello</th>\n",
       "      <th>hello this</th>\n",
       "      <th>is</th>\n",
       "      <th>is an</th>\n",
       "      <th>is another</th>\n",
       "      <th>is mellow</th>\n",
       "      <th>mellow</th>\n",
       "      <th>sentence</th>\n",
       "      <th>this</th>\n",
       "      <th>this is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        an  an sentence  another  another sentence  hello  hello hello  \\\n",
       "Text 1   1            1        0                 0      1            0   \n",
       "Text 2   0            0        1                 1      1            0   \n",
       "Text 3   0            0        0                 0      3            2   \n",
       "\n",
       "        hello this  is  is an  is another  is mellow  mellow  sentence  this  \\\n",
       "Text 1           1   1      1           0          0       0         1     1   \n",
       "Text 2           1   1      0           1          0       0         1     1   \n",
       "Text 3           1   1      0           0          1       1         0     1   \n",
       "\n",
       "        this is  \n",
       "Text 1        1  \n",
       "Text 2        1  \n",
       "Text 3        1  "
      ]
     },
     "metadata": {},
     "execution_count": 424
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TFIDF\n",
    "A problem with the Bag of Words approach is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much âinformational contentâ. Also, it will give more weight to longer documents than shorter documents.\n",
    "\n",
    "One approach is to rescale the frequency of words by how often they appear in all documents so that the scores for frequent words like âtheâ that are also frequent across all documents are penalized. This approach to scoring is called Term Frequency-Inverse Document Frequency, or TF-IDF for short, where:\n",
    "\n",
    "- **Term Frequency**: is a scoring of the frequency of the word in the current document.\n",
    "- **Inverse Document Frequency**: is a scoring of how rare the word is across documents."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "source": [
    "#Same approach for the TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "texts_tfidf=tfidf.fit_transform(texts)\n",
    "tokens = tfidf.get_feature_names()\n",
    "pd.DataFrame(data=texts_tfidf.toarray(), index=['Text 1', 'Text 2', \"Text 3\"], columns=tokens)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>another</th>\n",
       "      <th>hello</th>\n",
       "      <th>is</th>\n",
       "      <th>mellow</th>\n",
       "      <th>sentence</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text 1</th>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469417</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617227</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.364544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469417</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text 3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805627</td>\n",
       "      <td>0.268542</td>\n",
       "      <td>0.454682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              an   another     hello        is    mellow  sentence      this\n",
       "Text 1  0.617227  0.000000  0.364544  0.364544  0.000000  0.469417  0.364544\n",
       "Text 2  0.000000  0.617227  0.364544  0.364544  0.000000  0.469417  0.364544\n",
       "Text 3  0.000000  0.000000  0.805627  0.268542  0.454682  0.000000  0.268542"
      ]
     },
     "metadata": {},
     "execution_count": 425
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center> Apply to the reviews"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bag Of Words 1-gram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "source": [
    "%%time\n",
    "bow_1gram = CountVectorizer(lowercase=False)\n",
    "\n",
    "train_bow_1gram = bow_1gram.fit_transform(X_train)\n",
    "valid_bow_1gram= bow_1gram.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3.3 s, sys: 91 ms, total: 3.4 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bag Of Words 1-2-grams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "source": [
    "%%time\n",
    "bow_2grams = CountVectorizer(lowercase=False,ngram_range=(1,2))\n",
    "train_bow_2grams = bow_2grams.fit_transform(X_train)\n",
    "valid_bow_2grams = bow_2grams.transform(X_test)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 10.4 s, sys: 352 ms, total: 10.7 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "source": [
    "bow_1gram.get_feature_names()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaaaah',\n",
       " 'aaaaah',\n",
       " 'aaaaatch',\n",
       " 'aaaahhhhhhh',\n",
       " 'aaaand',\n",
       " 'aaaarrgh',\n",
       " 'aaah',\n",
       " 'aaargh',\n",
       " 'aaaugh',\n",
       " 'aachen',\n",
       " 'aadha',\n",
       " 'aag',\n",
       " 'aage',\n",
       " 'aaghh',\n",
       " 'aaip',\n",
       " 'aaja',\n",
       " 'aakash',\n",
       " 'aaker',\n",
       " 'aakrosh',\n",
       " 'aaliyah',\n",
       " 'aames',\n",
       " 'aamir',\n",
       " 'aan',\n",
       " 'aankh',\n",
       " 'aankhen',\n",
       " 'aap',\n",
       " 'aapke',\n",
       " 'aapkey',\n",
       " 'aardman',\n",
       " 'aargh',\n",
       " 'aaron',\n",
       " 'aarp',\n",
       " 'aarrrgh',\n",
       " 'aatish',\n",
       " 'aauugghh',\n",
       " 'aavjo',\n",
       " 'aaww',\n",
       " 'ab',\n",
       " 'aback',\n",
       " 'abadi',\n",
       " 'abahy',\n",
       " 'abanazer',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abanks',\n",
       " 'abas',\n",
       " 'abashed',\n",
       " 'abashidze',\n",
       " 'abatement',\n",
       " 'abating',\n",
       " 'abattoirs',\n",
       " 'abba',\n",
       " 'abbad',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbey',\n",
       " 'abbie',\n",
       " 'abbot',\n",
       " 'abbots',\n",
       " 'abbott',\n",
       " 'abbreviated',\n",
       " 'abbu',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abcd',\n",
       " 'abdic',\n",
       " 'abdicating',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abdu',\n",
       " 'abduct',\n",
       " 'abducted',\n",
       " 'abductee',\n",
       " 'abducting',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abductor',\n",
       " 'abductors',\n",
       " 'abducts',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'abercrombie',\n",
       " 'abernathy',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberystwyth',\n",
       " 'abetted',\n",
       " 'abeyance',\n",
       " 'abgail',\n",
       " 'abhay',\n",
       " 'abhays',\n",
       " 'abhi',\n",
       " 'abhijeet',\n",
       " 'abhimaan',\n",
       " 'abhishek',\n",
       " 'abhor',\n",
       " 'abhorrence',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abide',\n",
       " 'abides',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'abigil',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abilityof',\n",
       " 'abishai',\n",
       " 'abject',\n",
       " 'abjectly',\n",
       " 'abkani',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abm',\n",
       " 'abner',\n",
       " 'abnormal',\n",
       " 'abnormally',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abodes',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolition',\n",
       " 'abolitionism',\n",
       " 'abolitionists',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'abominator',\n",
       " 'abominibal',\n",
       " 'aboooot',\n",
       " 'aborigin',\n",
       " 'aboriginal',\n",
       " 'aboriginals',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'aboriginies',\n",
       " 'aborigins',\n",
       " 'aborigone',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortionist',\n",
       " 'abortionists',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'aborts',\n",
       " 'abos',\n",
       " 'abott',\n",
       " 'abound',\n",
       " 'abounded',\n",
       " 'abounding',\n",
       " 'abounds',\n",
       " 'about',\n",
       " 'aboutagirly',\n",
       " 'abouts',\n",
       " 'above',\n",
       " 'abovementioned',\n",
       " 'abracadabrantesque',\n",
       " 'abraham',\n",
       " 'abrahamic',\n",
       " 'abrahams',\n",
       " 'abrahms',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abrasively',\n",
       " 'abre',\n",
       " 'abreast',\n",
       " 'abridge',\n",
       " 'abridged',\n",
       " 'abril',\n",
       " 'abroad',\n",
       " 'abromowitz',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abs',\n",
       " 'absalom',\n",
       " 'abscessed',\n",
       " 'abscond',\n",
       " 'absconded',\n",
       " 'absconding',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absentminded',\n",
       " 'absentmindedly',\n",
       " 'abskani',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoluter',\n",
       " 'absolution',\n",
       " 'absolutlely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absolve',\n",
       " 'absolved',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbent',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'absoulely',\n",
       " 'absoutley',\n",
       " 'abstain',\n",
       " 'abstained',\n",
       " 'abstains',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstraction',\n",
       " 'abstractions',\n",
       " 'absurd',\n",
       " 'absurder',\n",
       " 'absurdism',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'absurdness',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abunch',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abut',\n",
       " 'abutted',\n",
       " 'abuzz',\n",
       " 'aby',\n",
       " 'abydos',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'abyssmal',\n",
       " 'ac',\n",
       " 'acadamy',\n",
       " 'academe',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academically',\n",
       " 'academics',\n",
       " 'academies',\n",
       " 'academy',\n",
       " 'acadmey',\n",
       " 'acapella',\n",
       " 'acapulco',\n",
       " 'acc',\n",
       " 'accede',\n",
       " 'acceded',\n",
       " 'accedes',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accentuates',\n",
       " 'accentuating',\n",
       " 'accentuation',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptation',\n",
       " 'accepted',\n",
       " 'acceptence',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'accesible',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessorizing',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentee',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclaims',\n",
       " 'acclamation',\n",
       " 'acclimate',\n",
       " 'acclimation',\n",
       " 'accolade',\n",
       " 'accoladed',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accompagnied',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accorded',\n",
       " 'accordian',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'accorsi',\n",
       " 'accost',\n",
       " 'accosted',\n",
       " 'accosts',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountancy',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accouterments',\n",
       " 'accredited',\n",
       " 'accrued',\n",
       " 'accrutements',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accumulator',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accursed',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accusatory',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusers',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'acd',\n",
       " 'ace',\n",
       " 'aced',\n",
       " 'acedmy',\n",
       " 'acerbic',\n",
       " 'acerbity',\n",
       " 'aces',\n",
       " 'acetylene',\n",
       " 'achad',\n",
       " 'achala',\n",
       " 'acharya',\n",
       " 'achcha',\n",
       " 'ache',\n",
       " 'acheaology',\n",
       " 'ached',\n",
       " 'achero',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieveing',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achievers',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achile',\n",
       " 'achilleas',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achive',\n",
       " 'achra',\n",
       " 'achterbusch',\n",
       " 'acid',\n",
       " 'acidently',\n",
       " 'acidic',\n",
       " 'acidity',\n",
       " 'acids',\n",
       " 'acin',\n",
       " 'aciton',\n",
       " 'ack',\n",
       " 'acker',\n",
       " 'ackerman',\n",
       " 'ackland',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acknowledgments',\n",
       " 'ackroyd',\n",
       " 'acl',\n",
       " 'aclear',\n",
       " 'aclu',\n",
       " 'acme',\n",
       " 'acmetropolis',\n",
       " 'acne',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'acomplication',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acp',\n",
       " 'acquaint',\n",
       " 'acquaintaces',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquaints',\n",
       " 'acquart',\n",
       " 'acquiesce',\n",
       " 'acquiescence',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquit',\n",
       " 'acquitane',\n",
       " 'acquits',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrimonious',\n",
       " 'acrobat',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acronym',\n",
       " 'acronymic',\n",
       " 'acropolis',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'actelone',\n",
       " 'actess',\n",
       " 'acteurs',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'actingjob',\n",
       " 'actingwise',\n",
       " 'action',\n",
       " 'actiona',\n",
       " 'actioneer',\n",
       " 'actioner',\n",
       " 'actioners',\n",
       " 'actionless',\n",
       " 'actionmovie',\n",
       " 'actionpacked',\n",
       " 'actions',\n",
       " 'actionscenes',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'actives',\n",
       " 'activest',\n",
       " 'activision',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actores',\n",
       " 'actors',\n",
       " 'actra',\n",
       " 'actreesess',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actriss',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualities',\n",
       " 'actuality',\n",
       " 'actualization',\n",
       " 'actualize',\n",
       " 'actuall',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actuelly',\n",
       " 'actullly',\n",
       " 'acturly',\n",
       " 'acual',\n",
       " 'acually',\n",
       " 'acuity',\n",
       " 'acumen',\n",
       " 'acus',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adabted',\n",
       " 'adachi',\n",
       " 'adage',\n",
       " 'adair',\n",
       " 'adalbert',\n",
       " 'adam',\n",
       " 'adama',\n",
       " 'adamant',\n",
       " 'adamantium',\n",
       " 'adamantly',\n",
       " 'adamos',\n",
       " 'adams',\n",
       " 'adamson',\n",
       " 'adapt',\n",
       " 'adaptable',\n",
       " 'adaptaion',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adaptions',\n",
       " 'adaptor',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'addam',\n",
       " 'addams',\n",
       " 'addario',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'adder',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addio',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'additives',\n",
       " 'addled',\n",
       " 'addons',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'ade',\n",
       " 'adela',\n",
       " 'adelade',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adelin',\n",
       " 'adeline',\n",
       " 'adelle',\n",
       " 'ademir',\n",
       " 'aden',\n",
       " 'adenine',\n",
       " 'adenoidal',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adeptness',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adgth',\n",
       " 'adhd',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adherence',\n",
       " 'adherents',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adhesive',\n",
       " 'adi',\n",
       " 'adibah',\n",
       " 'adiego',\n",
       " 'adien',\n",
       " 'adieu',\n",
       " 'adios',\n",
       " 'aditya',\n",
       " 'adj',\n",
       " 'adjacent',\n",
       " 'adjani',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjournment',\n",
       " 'adjunct',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjuster',\n",
       " 'adjustin',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjusts',\n",
       " 'adkins',\n",
       " 'adlai',\n",
       " 'adle',\n",
       " 'adler',\n",
       " 'adm',\n",
       " 'adma',\n",
       " 'adman',\n",
       " 'admarible',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'adminsitrative',\n",
       " 'admira',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admiralty',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirees',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admissible',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitedly',\n",
       " 'admits',\n",
       " 'admitt',\n",
       " 'admittadly',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admittingly',\n",
       " 'admonish',\n",
       " 'admonishes',\n",
       " 'admonishing',\n",
       " 'admonition',\n",
       " 'adnan',\n",
       " 'adnausem',\n",
       " 'ado',\n",
       " 'adobe',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adolf',\n",
       " 'adolfo',\n",
       " 'adolph',\n",
       " 'adolphs',\n",
       " 'adone',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoptee',\n",
       " 'adoptees',\n",
       " 'adopter',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adoree',\n",
       " 'adores',\n",
       " 'adoring',\n",
       " 'adoringly',\n",
       " 'adorned',\n",
       " 'adorning',\n",
       " 'adorns',\n",
       " 'adr',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adreno',\n",
       " 'adreon',\n",
       " 'adrian',\n",
       " 'adriana',\n",
       " 'adrianne',\n",
       " 'adriano',\n",
       " 'adriatic',\n",
       " 'adrien',\n",
       " 'adrienne',\n",
       " 'adriensen',\n",
       " 'adrift',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'ads',\n",
       " 'adt',\n",
       " 'adulating',\n",
       " 'adulation',\n",
       " 'adulhood',\n",
       " 'adult',\n",
       " 'adulterate',\n",
       " 'adulterated',\n",
       " 'adulterer',\n",
       " 'adulteress',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adultism',\n",
       " 'adultry',\n",
       " 'adults',\n",
       " 'adv',\n",
       " 'advan',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advani',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventist',\n",
       " 'adventists',\n",
       " 'adventure',\n",
       " 'adventured',\n",
       " 'adventurer',\n",
       " 'adventurers',\n",
       " 'adventures',\n",
       " 'adventuresome',\n",
       " 'adventurous',\n",
       " 'adventurously',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'adversities',\n",
       " 'adversity',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advices',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisedly',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'ae',\n",
       " 'aegean',\n",
       " 'aegerter',\n",
       " 'aeneid',\n",
       " 'aeon',\n",
       " 'aeons',\n",
       " 'aerial',\n",
       " 'aero',\n",
       " 'aerobic',\n",
       " 'aerobicide',\n",
       " 'aerobics',\n",
       " 'aerodynamic',\n",
       " 'aerodynamics',\n",
       " 'aeronautical',\n",
       " 'aeroplane',\n",
       " 'aerosol',\n",
       " 'aesir',\n",
       " 'aesop',\n",
       " 'aesthete',\n",
       " 'aesthetic',\n",
       " 'aesthetical',\n",
       " 'aesthetically',\n",
       " 'aestheticism',\n",
       " 'aesthetics',\n",
       " 'aetheist',\n",
       " 'af',\n",
       " 'afar',\n",
       " 'afer',\n",
       " 'afest',\n",
       " 'afew',\n",
       " 'aff',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affaire',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affectations',\n",
       " 'affected',\n",
       " 'affectedly',\n",
       " 'affecting',\n",
       " 'affectingly',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affective',\n",
       " 'affects',\n",
       " 'affectts',\n",
       " 'afficinados',\n",
       " 'afficionado',\n",
       " 'afficionados',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affinit',\n",
       " 'affinities',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmations',\n",
       " 'affirmative',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affix',\n",
       " 'affixed',\n",
       " 'affleck',\n",
       " 'afflect',\n",
       " 'afflict',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'afflictions',\n",
       " 'affluence',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affords',\n",
       " 'affront',\n",
       " 'affronting',\n",
       " 'affronts',\n",
       " 'afgahnistan',\n",
       " 'afgan',\n",
       " 'afgani',\n",
       " 'afganistan',\n",
       " 'afghan',\n",
       " 'afghanastan',\n",
       " 'afghani',\n",
       " 'afghanistan',\n",
       " 'afghans',\n",
       " 'afi',\n",
       " 'afican',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afield',\n",
       " 'afilm',\n",
       " 'afl',\n",
       " 'aflac',\n",
       " 'aflame',\n",
       " 'afleck',\n",
       " 'afloat',\n",
       " 'afm',\n",
       " 'afonya',\n",
       " 'afoot',\n",
       " 'afore',\n",
       " 'aforementioned',\n",
       " 'aforesaid',\n",
       " 'aformentioned',\n",
       " 'afortunately',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanism',\n",
       " 'africans',\n",
       " 'afrika',\n",
       " 'afrikaans',\n",
       " 'afro',\n",
       " 'afroamerican',\n",
       " 'afrovideo',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afterbirth',\n",
       " 'aftereffects',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'afterlives',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterschool',\n",
       " 'aftershock',\n",
       " 'afterstory',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterthoughts',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'afterwhile',\n",
       " 'afterwords',\n",
       " 'aftra',\n",
       " 'afv',\n",
       " 'ag',\n",
       " 'agaaaain',\n",
       " 'agae',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agamemnon',\n",
       " 'agape',\n",
       " 'agar',\n",
       " 'agatha',\n",
       " 'agbayani',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agee',\n",
       " 'ageing',\n",
       " 'ageless',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ager',\n",
       " 'ages',\n",
       " 'agey',\n",
       " 'aggelopoulos',\n",
       " 'aggh',\n",
       " 'aggie',\n",
       " 'aggrandizing',\n",
       " 'aggravated',\n",
       " 'aggravates',\n",
       " 'aggravating',\n",
       " 'aggravatingly',\n",
       " 'aggravation',\n",
       " 'aggresive',\n",
       " 'aggressed',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressiveness',\n",
       " 'aggressor',\n",
       " 'aggressors',\n",
       " 'aggrieved',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 438
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TFIDF 1-gram"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "source": [
    "%%time\n",
    "tfidf_1gram       = TfidfVectorizer()\n",
    "train_tfidf_1gram = tfidf_1gram.fit_transform(X_train)\n",
    "valid_tfidf_1gram = tfidf_1gram.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 3.06 s, sys: 69.1 ms, total: 3.13 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TFIDF 1-2-grams"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "source": [
    "%%time\n",
    "tfidf_2grams      = TfidfVectorizer(ngram_range=(1,2))\n",
    "train_tfidf_2grams = tfidf_2grams.fit_transform(X_train)\n",
    "valid_tfidf_2grams = tfidf_2grams.transform(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 11.1 s, sys: 507 ms, total: 11.6 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "source": [
    "data = [\n",
    "    (\"BOW 1gram\",   train_bow_1gram, valid_bow_1gram),\n",
    "    (\"BOW 2grams\",  train_bow_2grams, valid_bow_2grams),\n",
    "    (\"TFIDF 1gram\", train_tfidf_1gram, valid_tfidf_1gram),\n",
    "    (\"TFIDF 2grams\",train_tfidf_2grams, valid_tfidf_2grams)\n",
    "]\n",
    "\n",
    "print(\"BOW 1gram   \", train_bow_1gram.shape)\n",
    "print(\"BOW 2grams  \", train_bow_2grams.shape)\n",
    "print(\"TFIDF 1gram \", train_tfidf_1gram.shape)\n",
    "print(\"TFIDF 2grams\", train_tfidf_2grams.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW 1gram    (20000, 67047)\n",
      "BOW 2grams   (20000, 1282511)\n",
      "TFIDF 1gram  (20000, 67047)\n",
      "TFIDF 2grams (20000, 1282511)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center> ML Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes (<1 s)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "source": [
    "\n",
    "for name, x_train, x_valid in data:\n",
    "    start=time.time()\n",
    "    model = MultinomialNB()\n",
    "    model.fit(x_train,y_train)\n",
    "    t=time.time()-start\n",
    "    a = accuracy_score(y_test, model.predict(x_valid))\n",
    "    print(name, \"\\tAccuracy:\\t\", a, \"\\tTime:\\t\", t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW 1gram \tAccuracy:\t 0.8394 \tTime:\t 0.02644205093383789\n",
      "BOW 2grams \tAccuracy:\t 0.8752 \tTime:\t 0.14758682250976562\n",
      "TFIDF 1gram \tAccuracy:\t 0.8692 \tTime:\t 0.021232128143310547\n",
      "TFIDF 2grams \tAccuracy:\t 0.8854 \tTime:\t 0.14233016967773438\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression (30s)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "source": [
    "for name, x_train, x_valid in data:\n",
    "   start1=time.time()\n",
    "   model1 = LogisticRegression()\n",
    "   model1.fit(x_train,y_train)\n",
    "   t1=time.time()-start1\n",
    "   a1 =accuracy_score(y_test, model1.predict(x_valid))\n",
    "\n",
    "   print(name, \"\\tAccuracy:\\t\", a1, \"\\tTime:\\t\", t1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/saidalikhonalikhonov/opt/anaconda3/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW 1gram \tAccuracy:\t 0.8654 \tTime:\t 1.5433447360992432\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/saidalikhonalikhonov/opt/anaconda3/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW 2grams \tAccuracy:\t 0.8858 \tTime:\t 44.67916703224182\n",
      "TFIDF 1gram \tAccuracy:\t 0.8872 \tTime:\t 1.3075332641601562\n",
      "TFIDF 2grams \tAccuracy:\t 0.8902 \tTime:\t 47.26083993911743\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest (10+90+6+22 seconds)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "source": [
    "for name, x_train, x_valid in data:\n",
    "    start2=time.time()\n",
    "    model2= RandomForestClassifier()\n",
    "    model2.fit(x_train,y_train)\n",
    "    t2=time.time()-start2\n",
    "    a2 =accuracy_score(y_test, model2.predict(x_valid))\n",
    "    print(name, \"\\tAccuracy:\\t\", a2, \"\\tTime:\\t\", t2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BOW 1gram \tAccuracy:\t 0.8436 \tTime:\t 28.10767912864685\n",
      "BOW 2grams \tAccuracy:\t 0.8456 \tTime:\t 134.126690864563\n",
      "TFIDF 1gram \tAccuracy:\t 0.8388 \tTime:\t 25.503247022628784\n",
      "TFIDF 2grams \tAccuracy:\t 0.845 \tTime:\t 126.75553512573242\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 386
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be7f91b8a86516165fcb6cb0d2d574b7f158dfa612c4d7a1e53febf57ef86532"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('new_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}